{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "mkdir: cannot create directory \u2018Case2\u2019: File exists\nCase18_seg1.mat\t\t\t  debug\t\t\tmtspec.py\nCase1_seg10.mat\t\t\t  fcn_shannon_entro.py\t__pycache__\nCase1_seg11.mat\t\t\t  full_pipeline.py\truntime.py\nCase1_seg12.mat\t\t\t  full_pipeline.py.bac\tspark-warehouse\nCase1_seg1.mat\t\t\t  get_features.py\ttemp\nCase2\t\t\t\t  get_features.pyc\tTeraGen-1TB\nCase5_seg1.mat\t\t\t  MGH-TEST-01\t\ttest2.mat\ncompute_spectrogram_sunhaoqi.py   MGH-TEST-02\ncompute_spectrogram_sunhaoqi.pyc  MGH-TEST-7P\n"
                }
            ], 
            "source": "!mkdir Case2\n!ls\n"
        }, 
        {
            "execution_count": 20, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Collecting nitime\n  Downloading nitime-0.7-py2-none-any.whl (4.0MB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4.0MB 267kB/s \n\u001b[?25hRequirement already satisfied: scipy in /usr/local/src/bluemix_jupyter_bundle.v47/notebook/lib/python2.7/site-packages (from nitime)\nRequirement already satisfied: numpy in /gpfs/global_fs01/sym_shared/YPProdSpark/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages (from nitime)\nRequirement already satisfied: matplotlib in /usr/local/src/bluemix_jupyter_bundle.v47/notebook/lib/python2.7/site-packages (from nitime)\nRequirement already satisfied: python-dateutil in /gpfs/global_fs01/sym_shared/YPProdSpark/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages (from matplotlib->nitime)\nRequirement already satisfied: pytz in /gpfs/global_fs01/sym_shared/YPProdSpark/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages (from matplotlib->nitime)\nRequirement already satisfied: cycler in /usr/local/src/bluemix_jupyter_bundle.v47/notebook/lib/python2.7/site-packages (from matplotlib->nitime)\nRequirement already satisfied: pyparsing!=2.0.4,>=1.5.6 in /usr/local/src/bluemix_jupyter_bundle.v47/notebook/lib/python2.7/site-packages (from matplotlib->nitime)\nRequirement already satisfied: six>=1.5 in /usr/local/src/bluemix_jupyter_bundle.v47/notebook/lib/python2.7/site-packages (from python-dateutil->matplotlib->nitime)\nInstalling collected packages: nitime\nSuccessfully installed nitime-0.7\n"
                }
            ], 
            "source": "!pip install nitime"
        }, 
        {
            "execution_count": 19, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Collecting joblib\n  Downloading joblib-0.11-py2.py3-none-any.whl (176kB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 184kB 2.2MB/s \n\u001b[?25hInstalling collected packages: joblib\nSuccessfully installed joblib-0.11\n"
                }
            ], 
            "source": "!pip install joblib"
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Collecting hdf5storage\n  Downloading hdf5storage-0.1.14-py2.py3-none-any.whl (55kB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 61kB 4.0MB/s \n\u001b[?25hInstalling collected packages: hdf5storage\nSuccessfully installed hdf5storage-0.1.14\n"
                }
            ], 
            "source": "!pip install hdf5storage"
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Collecting spectrum\n  Downloading spectrum-0.6.2.tar.gz (92kB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 102kB 5.4MB/s \n\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/src/bluemix_jupyter_bundle.v47/notebook/lib/python2.7/site-packages (from spectrum)\nRequirement already satisfied: numpy in /gpfs/global_fs01/sym_shared/YPProdSpark/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages (from spectrum)\nRequirement already satisfied: scipy in /usr/local/src/bluemix_jupyter_bundle.v47/notebook/lib/python2.7/site-packages (from spectrum)\nCollecting easydev (from spectrum)\n  Downloading easydev-0.9.34.tar.gz (53kB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 61kB 4.3MB/s \n\u001b[?25hRequirement already satisfied: python-dateutil in /gpfs/global_fs01/sym_shared/YPProdSpark/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages (from matplotlib->spectrum)\nRequirement already satisfied: pytz in /gpfs/global_fs01/sym_shared/YPProdSpark/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages (from matplotlib->spectrum)\nRequirement already satisfied: cycler in /usr/local/src/bluemix_jupyter_bundle.v47/notebook/lib/python2.7/site-packages (from matplotlib->spectrum)\nRequirement already satisfied: pyparsing!=2.0.4,>=1.5.6 in /usr/local/src/bluemix_jupyter_bundle.v47/notebook/lib/python2.7/site-packages (from matplotlib->spectrum)\nCollecting colorama (from easydev->spectrum)\n  Downloading colorama-0.3.9-py2.py3-none-any.whl\nRequirement already satisfied: pexpect in /usr/local/src/bluemix_jupyter_bundle.v47/notebook/lib/python2.7/site-packages (from easydev->spectrum)\nRequirement already satisfied: six>=1.5 in /usr/local/src/bluemix_jupyter_bundle.v47/notebook/lib/python2.7/site-packages (from python-dateutil->matplotlib->spectrum)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/src/bluemix_jupyter_bundle.v47/notebook/lib/python2.7/site-packages (from pexpect->easydev->spectrum)\nBuilding wheels for collected packages: spectrum, easydev\n  Running setup.py bdist_wheel for spectrum ... \u001b[?25l-\b \b\\\b \bdone\n\u001b[?25h  Stored in directory: /gpfs/fs01/user/seff-34c2f0d3dcc620-a916a00b641d/.cache/pip/wheels/8c/57/db/35bde7acfd729f37526a6765ccbe4afe36fded493f1e65d675\n  Running setup.py bdist_wheel for easydev ... \u001b[?25l-\b \bdone\n\u001b[?25h  Stored in directory: /gpfs/fs01/user/seff-34c2f0d3dcc620-a916a00b641d/.cache/pip/wheels/56/f1/d6/b72aa4482beed23f727860bf69a8efee1c60836abf4ec2e779\nSuccessfully built spectrum easydev\nInstalling collected packages: colorama, easydev, spectrum\nSuccessfully installed colorama-0.3.9 easydev-0.9.34 spectrum-0.6.2\n"
                }
            ], 
            "source": "!pip install spectrum"
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import os, sys, copy, time\nfrom sys import stdin, stdout, stderr\n\n# Test libraries\nfrom scipy.signal import butter, filtfilt\n\n# Loading\nimport hdf5storage\nimport h5py\nimport pylab\n\n# numpy cleaning\n\nfrom numpy.core.defchararray import lower\nfrom scipy.linalg import schur\n\n# tools\nfrom scipy.io import loadmat\nfrom scipy.special import gamma\nfrom numpy import rint as fix\nfrom scipy.linalg import schur\nimport numpy\nfrom numpy import sqrt, prod, exp, log, dot, multiply, inf\nfrom numpy.fft import fft2\nfrom numpy.linalg import inv\nfrom numpy.linalg import qr\nfrom numpy import inf, empty\n\n# spectral\nfrom spectrum import pmtm\nimport spectrum\n\n# features\nfrom numpy import mean, std\nfrom scipy.stats import kurtosis\nfrom matplotlib.mlab import prctile"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "# Test loading from file\n\nfrom libhelpers import test_lib\n\ntest_lib()"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "# Test mappartition\n# TODO: distribute function to cluster"
        }, 
        {
            "execution_count": 12, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "good\n"
                }, 
                {
                    "ename": "NameError", 
                    "evalue": "name 'getsizeof' is not defined", 
                    "traceback": [
                        "\u001b[1;31m\u001b[0m", 
                        "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)", 
                        "\u001b[1;32m<ipython-input-12-e6cc76eacd02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Case1_seg1.mat\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m \u001b[0mgetsizeof\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n", 
                        "\u001b[1;31mNameError\u001b[0m: name 'getsizeof' is not defined"
                    ], 
                    "output_type": "error"
                }
            ], 
            "source": "# Test calling hdf5 loader\nimport h5py\nfrom io import StringIO\nimport requests\nimport json\nimport pandas as pd\n\nobjStorCred = {\n  \"auth_url\": \"https://identity.open.softlayer.com\",\n  \"project\": \"object_storage_20ff227d_d66c_495a_a316_cd99e80a9e6f\",\n  \"projectId\": \"a9fb4d478e3d40a8bbd54c5a2ecf25a3\",\n  \"region\": \"dallas\",\n  \"userId\": \"6a4cc8251c1940179a6cccc9098a15e0\",\n  \"username\": \"admin_fd35793e7cf915d9a5a9c768b068029cf6d720b9\",\n  \"password\": \"kDTcKA2H(3eo5.G0\",\n  \"domainId\": \"a350f0fe7fb44571b29305706a12c95a\",\n  \"domainName\": \"1334933\",\n  \"role\": \"admin\"\n}\n\ndef getObjStoreFile(container, filename):\n    url1 = 'https://identity.open.softlayer.com/v3/auth/tokens'\n    data = {'auth': {'identity': {'methods': ['password'],\n            'password': {'user': {'name': objStorCred['username'],'domain': {'id': objStorCred['domainId']},\n            'password': objStorCred['password']}}}}}\n    headers1 = {'Content-Type': 'application/json'}\n    resp1 = requests.post(url=url1, data=json.dumps(data), headers=headers1)\n    resp1_body = resp1.json()\n    #print resp1_body\n    for e1 in resp1_body['token']['catalog']:\n        if(e1['type']=='object-store'):\n            for e2 in e1['endpoints']:\n                        if(e2['interface']=='public'and e2['region']=='dallas'):\n                            url2 = ''.join([e2['url'],'/', container, '/', filename])\n    s_subject_token = resp1.headers['x-subject-token']\n    headers2 = {'X-Auth-Token': s_subject_token, 'accept': 'application/json'}\n    resp2 = requests.get(url=url2, headers=headers2, stream=True)\n    if resp2.status_code == 200:\n        if not os.path.exists(os.path.dirname(filename)):\n            os.makedirs(os.path.dirname(filename))\n        with open(filename, 'wb') as f:\n            for chunk in resp2.iter_content(1024):\n                f.write(chunk)\n        return 'good'\n    else:\n        return 'bad'\n    \nprint getObjStoreFile(\"MGH\", \"Case1/Case1_seg1.mat\")\n\nf = h5py.File(\"Case1_seg1.mat\")\n#getsizeof(f)\n\n"
        }, 
        {
            "execution_count": 13, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 13, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[u'Fs', u'channels', u'data', u'start_time']"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "f.keys()"
        }, 
        {
            "execution_count": 16, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "(array([[ 255.99775]]), <type 'numpy.ndarray'>)\n(32, 9999999)\n"
                }
            ], 
            "source": "mat=hdf5storage.loadmat('Case1_seg1.mat')\nprint(mat['Fs'],mat['Fs'].__class__)\n\nprint(mat['data'].shape)\n\n"
        }, 
        {
            "execution_count": 46, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Case18_seg1.mat  MGH-TEST-01  MGH-TEST-02  MGH-TEST-7P\tspark-warehouse\r\n"
                }
            ], 
            "source": "!ls\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "('Loading', 'Case18_seg1.mat')\nopen\nclose\n('data', (9999999, 50), cellarray([[200.0]], dtype=object), cellarray([[u'07-29-2012 08:14:45']], dtype=object), cellarray([[u'C3   '],\n       [u'C4   '],\n       [u'O1   '],\n       [u'O2   '],\n       [u'A1   '],\n       [u'A2   '],\n       [u'Cz   '],\n       [u'F3   '],\n       [u'F4   '],\n       [u'F7   '],\n       [u'F8   '],\n       [u'Fz   '],\n       [u'Fp1  '],\n       [u'Fp2  '],\n       [u'Fpz  '],\n       [u'P3   '],\n       [u'P4   '],\n       [u'Pz   '],\n       [u'T3   '],\n       [u'T4   '],\n       [u'T5   '],\n       [u'T6   '],\n       [u'LOC  '],\n       [u'ROC  '],\n       [u'CHIN1'],\n       [u'CHIN2'],\n       [u'ECGL '],\n       [u'ECGR '],\n       [u'LAT1 '],\n       [u'LAT2 '],\n       [u'RAT1 '],\n       [u'RAT2 '],\n       [u'RFO1 '],\n       [u'RFO2 '],\n       [u'RFO3 '],\n       [u'RFO4 '],\n       [u'DIF5 '],\n       [u'DIF6 '],\n       [u'POS  '],\n       [u'LFO1 '],\n       [u'LFO2 '],\n       [u'LFO3 '],\n       [u'LFO4 '],\n       [u'DC6  '],\n       [u'DC7  '],\n       [u'DC8  '],\n       [u'DC9  '],\n       [u'DC10 '],\n       [u'OSAT '],\n       [u'PR   ']], dtype=object))\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/gpfs/fs01/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages/nitime/utils.py:551: RuntimeWarning: invalid value encountered in divide\n  d_k /= eigvals[:, None]*sdf_iter[None, :] + bband_sup[:,None]\n/gpfs/fs01/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages/numpy/lib/function_base.py:4116: RuntimeWarning: Invalid value encountered in percentile\n  else:\n"
                }
            ], 
            "source": "### Compute Spectrogram\n\n\nfrom joblib import Parallel, delayed\nimport numpy as np\nfrom scipy.signal import detrend\nimport nitime.algorithms as tsa\n\n\ndef compute_spec_each_seg(eeg_seg, NW, Fs):\n    \"\"\"\n    Input:\n    eeg_seg: numpy.array (point_num x channel_num)\n    NW: Time-halfbandwidth product, 2 or 3 or 4 or ... #taper = 2NW-1\n    Fs: sampling frequency in Hz\n    \n    Output:\n    mt_pxx: the spectrum (freq_num x channel_num)\n    freqs: frequencies (freq_num,)\n    \"\"\"\n    point_num, channel_num = eeg_seg.shape\n    nfft = max(1<<(point_num-1).bit_length(), point_num)\n    freqs = np.arange(0, Fs, Fs*1.0/nfft)[:nfft//2+1]  # list of frequencies\n\n    mt_pxx = np.zeros((len(freqs),channel_num))  # create the array to contain the spectrum\n\n    eeg_seg = detrend(eeg_seg, axis=0)  # remove the overall trend of the signal\n    for chi in range(channel_num):\n        _, pxx, _ = tsa.multi_taper_psd(eeg_seg[:,chi], Fs=Fs, NW=NW, adaptive=True, jackknife=False, low_bias=True, NFFT=nfft)\n        mt_pxx[:,chi] = pxx\n        \n    return mt_pxx, freqs\n\n\ndef mtspecgram_shq(eeg, movingwin, fpass, NW, Fs):\n    \"\"\"\n    Input:\n    eeg: numpy.array (signal_length x channel_num)\n    movingwin: [window length, window step] in seconds\n    fpass: [low, higher] in Hz\n    NW: Time-halfbandwidth product, 2 or 3 or 4 or ... #taper = 2NW-1\n    Fs: sampling frequency in Hz\n    \n    Output:\n    spect: the spectrogram (window_num x freq_num x channel_num)\n    stimes: window starting times (window_num,)\n    sfreqs: frequencies (freq_num,)\n    \"\"\"\n    signal_length, channel_num = eeg.shape\n    window_length = int(round(movingwin[0]*Fs))\n    window_step = int(round(movingwin[1]*Fs))\n    \n    window_start = np.arange(0,signal_length-window_length+1,window_step)  # starting point of each segment\n    window_num = len(window_start)\n    stimes = window_start*1./Fs\n    \n    n_jobs = 1  # number of cpus for parallel computing, -1 is all cpus\n    verbose = True  # verbosity in parallel computing\n    res = Parallel(n_jobs=n_jobs, verbose=verbose)(delayed(compute_spec_each_seg)(eeg[window_start[wi]:window_start[wi]+window_length,:], NW, Fs) for wi in range(window_num))\n        \n    sfreqs = res[0][1]\n    freq_good_ids = np.logical_and(sfreqs>=fpass[0], sfreqs<fpass[1])\n    sfreqs = sfreqs[freq_good_ids]\n    \n    spect = np.array([rr[0][freq_good_ids] for rr in res])  # the spectrogram\n        \n    return spect, stimes, sfreqs\n    \n    \n    \nif __name__ == '__main__':\n    #### 1.0 Loading data ####\n\n    # - input -\n    #dataPath = '/Data/'\n    #print('dataPath',dataPath)\n    \n    # - output -\n    #targetFolder = catstr('/Output/')\n    \n    fileName0='Case18_seg1.mat'\n    \n    print('Loading',fileName0)\n    #fp=dataPath +fileName0\n    fp=fileName0\n    with load_mat(fp):\n        matfile = load(fp)\n        Fs=cellarray(matfile['Fs'])\n        start_time = cellarray(matfile['start_time'])\n        # channels = cellarray((51,1))\n        channels=cellarray(matfile['channels'])\n        \n        eeg_data = matfile['data']\n\n    print('data',eeg_data.T.shape,Fs,start_time,channels)\n        \n    #### 1.1 Compute spectrograms ####\n    # just a toy example\n#    eeg = np.random.rand(10000,6)\n    \n    spect, stimes, sfreqs = mtspecgram_shq(eeg_data.T, [2,2], [0.5, 20], 2, 200)\n    print(spect.shape)\n    print(stimes.shape)\n    print(sfreqs.shape)\n    \n\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "import numpy as np\nimport sys\nfrom numpy import sqrt, prod, exp, log, dot, multiply, inf\nimport hdf5storage\n\ndef load(fp):\n    matfile=hdf5storage.loadmat(fp)\n    # print('Loading from %s' % fp)\n    return matfile\n\ndef size(a, b=0, nargout=1):\n    \"\"\"\n    >>> size(zeros(3,3)) + 1\n    matlabarray([[4, 4]])\n    \"\"\"\n    s = np.asarray(a).shape\n    if s is ():\n        return 1 if b else (1,) * nargout\n    # a is not a scalar\n    try:\n        if b:\n            return s[b - 1]\n        else:\n            return matlabarray(s) if nargout <= 1 else s\n    except IndexError:\n        return 1\n\ndef arange(start, stop, step=1, **kwargs):\n    \"\"\"\n    >>> a=arange(1,10) # 1:10\n    >>> size(a)\n    matlabarray([[ 1, 10]])\n    \"\"\"\n    return matlabarray(np.arange(start,\n                                 stop + 1,\n                                 step,\n                                 **kwargs).reshape(1, -1), **kwargs)\n\n\ndef cat(*args):\n    return matlabarray(np.concatenate([matlabarray(a) for a in args], axis=1)).reshape(-1)\n\n\nclass end(object):\n    def __add__(self, n):\n        self.n = n\n        return self\n\n    def __sub__(self, n):\n        self.n = -n\n        return self\n\ndef isvector_or_scalar(a):\n    \"\"\"\n    one-dimensional arrays having shape [N],\n    row and column matrices having shape [1 N] and\n    [N 1] correspondingly, and their generalizations\n    having shape [1 1 ... N ... 1 1 1].\n    Scalars have shape [1 1 ... 1].\n    Empty arrays dont count\n    \"\"\"\n    try:\n        return a.size and a.ndim - a.shape.count(1) <= 1\n    except:\n        return False\n\ndef isvector(a):\n    \"\"\"\n    one-dimensional arrays having shape [N],\n    row and column matrices having shape [1 N] and\n    [N 1] correspondingly, and their generalizations\n    having shape [1 1 ... N ... 1 1 1]\n    \"\"\"\n    try:\n        return a.ndim - a.shape.count(1) == 1\n    except:\n        return False\n\nclass matlabarray(np.ndarray):\n    \"\"\"\n    >>> matlabarray()\n    matlabarray([], shape=(0, 0), dtype=float64)\n    >>> matlabarray([arange(1,5), arange(1,5)])\n    matlabarray([1, 2, 3, 4, 5, 1, 2, 3, 4, 5])\n    >>> matlabarray([\"hello\",\"world\"])\n    matlabarray(\"helloworld\")\n    \"\"\"\n\n    def __new__(cls, a=[], dtype=None):\n        # print(a.__class__)\n        obj = np.array(a,\n                       dtype=dtype,\n                       copy=False,\n                       order=\"F\",\n                       ndmin=2).view(cls).copy(order=\"F\")\n        if obj.size == 0:\n            obj.shape = (0, 0)\n\n        # self.obj=obj\n        return obj\n\n    # def __array_finalize__(self,obj):\n\n    def __copy__(self):\n        return np.ndarray.copy(self, order=\"F\")\n\n    def __iter__(self):\n        \"\"\" must define iter or char won't work\"\"\"\n        return np.asarray(self).__iter__()\n\n    def compute_indices(self, index):\n        if not isinstance(index, tuple):\n            index = index,\n        if len(index) != 1 and len(index) != self.ndim:\n            raise IndexError\n        indices = []\n        for i, ix in enumerate(index):\n            if ix.__class__ is end:\n                indices.append(self.shape[i] - 1 + ix.n)\n            elif ix.__class__ is slice:\n                if self.size == 0 and ix.stop is None:\n                    raise IndexError\n                if len(index) == 1:\n                    n = self.size\n                else:\n                    n = self.shape[i]\n                indices.append(np.arange((ix.start or 1) - 1,\n                                         ix.stop or n,\n                                         ix.step or 1,\n                                         dtype=int))\n            else:\n                try:\n                    indices.append(int(ix) - 1)\n                except:\n                    indices.append(np.asarray(ix).astype(\"int32\") - 1)\n        if len(indices) == 2 and isvector(indices[0]) and isvector(indices[1]):\n            indices[0].shape = (-1, 1)\n            indices[1].shape = (-1,)\n        return tuple(indices)\n\n    def __getslice__(self, i, j):\n        if i == 0 and j == sys.maxsize:\n            return self.reshape(-1, 1, order=\"F\")\n        return self.__getitem__(slice(i, j))\n\n    def __getitem__(self, index):\n        return matlabarray(self.get(index))\n\n    def get(self, index):\n        # import pdb; pdb.set_trace()\n        indices = self.compute_indices(index)\n        if len(indices) == 1:\n            return np.ndarray.__getitem__(self.reshape(-1, order=\"F\"), indices)\n        else:\n            return np.ndarray.__getitem__(self, indices)\n\n    def __setslice__(self, i, j, value):\n        if i == 0 and j == sys.maxsize:\n            index = slice(None, None)\n        else:\n            index = slice(i, j)\n        self.__setitem__(index, value)\n\n    def sizeof(self, ix):\n        if isinstance(ix, int):\n            n = ix + 1\n        elif isinstance(ix, slice):\n            n = ix.stop\n        elif isinstance(ix, (list, np.ndarray)):\n            n = max(ix) + 1\n        else:\n            assert 0, ix\n        if not isinstance(n, int):\n            raise IndexError\n        return n\n\n    def __setitem__(self, index, value):\n        # import pdb; pdb.set_trace()\n        indices = self.compute_indices(index)\n        try:\n            if len(indices) == 1:\n                np.asarray(self).reshape(-1, order=\"F\").__setitem__(indices, value)\n            else:\n                np.asarray(self).__setitem__(indices, value)\n        except (ValueError, IndexError):\n            # import pdb; pdb.set_trace()\n            if not self.size:\n                new_shape = [self.sizeof(s) for s in indices]\n                self.resize(new_shape, refcheck=0)\n                np.asarray(self).__setitem__(indices, value)\n            elif len(indices) == 1:\n                # One-dimensional resize is only implemented for\n                # two cases:\n                #\n                # a. empty matrices having shape [0 0]. These\n                #    matries may be resized to any shape.  A[B]=C\n                #    where A=[], and B is specific -- A[1:10]=C\n                #    rather than A[:]=C or A[1:end]=C\n                if self.size and not isvector_or_scalar(self):\n                    raise IndexError(\"One-dimensional resize \"\n                                     \"works only on vectors, and \"\n                                     \"row and column matrices\")\n                # One dimensional resize of scalars creates row matrices\n                # ai = 3\n                # a(4) = 1\n                # 3 0 0 1\n                n = self.sizeof(indices[0])  # zero-based\n                if max(self.shape) == 1:\n                    new_shape = list(self.shape)\n                    new_shape[-1] = n\n                else:\n                    new_shape = [(1 if s == 1 else n) for s in self.shape]\n                self.resize(new_shape, refcheck=0)\n                np.asarray(self).reshape(-1, order=\"F\").__setitem__(indices, value)\n            else:\n                new_shape = list(self.shape)\n                if self.flags[\"C_CONTIGUOUS\"]:\n                    new_shape[0] = self.sizeof(indices[0])\n                elif self.flags[\"F_CONTIGUOUS\"]:\n                    new_shape[-1] = self.sizeof(indices[-1])\n                self.resize(new_shape, refcheck=0)\n                np.asarray(self).__setitem__(indices, value)\n\n    def __repr__(self):\n        return self.__class__.__name__ + repr(np.asarray(self))[5:]\n\n    def __str__(self):\n        return str(np.asarray(self))\n\n    def __add__(self, other):\n        return matlabarray(np.asarray(self) + np.asarray(other))\n\n    def __neg__(self):\n        return matlabarray(np.asarray(self).__neg__())\n\n\nclass cellarray(matlabarray):\n    \"\"\"\n    Cell array corresponds to matlab ``{}``\n\n\n    \"\"\"\n\n    def __new__(cls, a=[]):\n        \"\"\"\n        Create a cell array and initialize it with a.\n        Without arguments, create an empty cell array.\n\n        Parameters:\n        a : list, ndarray, matlabarray, etc.\n\n        >>> a=cellarray([123,\"hello\"])\n        >>> print(a.shape)\n        (1, 2)\n\n        >>> print (a[1])\n        123\n\n        >>> print (a[2])\n        hello\n\n        >>> print(a)\n        [[123,'hello']]\n\n        >>> print('hello' in a)\n\n        >>> print(strcmp(a,'hello'))\n        True\n        \"\"\"\n        obj = np.array(a,\n                       dtype=object,\n                       order=\"F\",\n                       ndmin=2).view(cls).copy(order=\"F\")\n        if obj.size == 0:\n            obj.shape = (0, 0)\n        return obj\n\n    def __getitem__(self, index):\n        return self.get(index)\n\n\n    # def __str__(self):\n    #        if self.ndim == 0:\n    #            return \"\"\n    #        if self.ndim == 1:\n    #            return \"\".join(s for s in self)\n    #        if self.ndim == 2:\n    #            return \"\\n\".join(\"\".join(s) for s in self)\n    #        raise NotImplementedError\n\ndef cell(*args):\n    if len(args) == 1:\n        args += args\n    return cellarray(np.zeros(args, dtype=object, order=\"F\"))\n\n\ndef copy(a):\n    return matlabarray(np.asanyarray(a).copy(order=\"F\"))\n\n\ndef find(a, n=None, d=None, nargout=1):\n    if d:\n        raise NotImplementedError\n\n    # there is no promise that nonzero or flatnonzero\n    # use or will use indexing of the argument without\n    # converting it to array first.  So we use asarray\n    # instead of asanyarray\n    if nargout == 1:\n        i = np.flatnonzero(np.asarray(a)).reshape(1, -1) + 1\n        if n is not None:\n            i = i.take(n)\n        return matlabarray(i)\n    if nargout == 2:\n        i, j = np.nonzero(np.asarray(a))\n        if n is not None:\n            i = i.take(n)\n            j = j.take(n)\n        return (matlabarray((i + 1).reshape(-1, 1)),\n                matlabarray((j + 1).reshape(-1, 1)))\n    raise NotImplementedError\n\n\ndef disp(*args):\n    print(args)\n    \n    \ndef catstr(*arg):\n    \"\"\"\n    targetFolder='c:'\n    fileName0='cdg'\n\n    print(catstr(targetFolder, '/filtered_data_', fileName0))\n\n\n    \"\"\"\n\n    return \"\".join(arg)\n\n\nclass Dict2Obj(object):\n    \"\"\"\n    Turns a dictionary into a class\n    \"\"\"\n\n    # ----------------------------------------------------------------------\n    def __init__(self, dictionary):\n        \"\"\"Constructor\"\"\"\n        for key in dictionary:\n            setattr(self, key, dictionary[key])    "
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "from __future__ import division\nimport numpy as np\nfrom spectrum import dpss\nfrom scipy import signal\nimport scipy.io\n\n\"\"\"\nmultitaper spectrogram\n\n\"\"\"\n\ndef change_row_to_column(data):\n    \"\"\"\n    row into column vector\n\n    :param data:\n    :return:\n    \"\"\"\n    print(len(data.shape))\n    if len(data.shape) > 1:\n        N, C = data.shape\n        if (N == 1):\n            data = data.T\n    else:\n        print(data.shape[0], 1)\n\n        data = data.reshape((data.shape[0], 1))\n    print(data.shape)\n    return data\n\n\ndef nextpow2(n):\n    if np.any(n < 0):\n        raise ValueError(\"n should be > 0\")\n\n    if np.isscalar(n):\n        f, p = np.frexp(n)\n        if f == 0.5:\n            return p - 1\n        elif np.isfinite(f):\n            return p\n        else:\n            return f\n    else:\n        f, p = np.frexp(n)\n        res = f\n        bet = np.isfinite(f)\n        exa = (f == 0.5)\n        res[bet] = p[bet]\n        res[exa] = p[exa] - 1\n        return res\n\n\ndef getfgrid(Fs, nfft, fpass):\n    \"\"\"\n    get freq grid given fft\n    \"\"\"\n    df = Fs / nfft\n    f = np.arange(0, Fs, df)\n    l = len(f)\n    if f[l - 1] != Fs:\n        f = np.append(f, Fs)\n    f = f[0:nfft]\n    if len(fpass) != 1:\n        findx = (np.where((f >= fpass[0]) & (f <= fpass[1])))\n    else:\n        min_index, min_value = min(enumerate(f - fpass[2]), key=np.operator.itemgetter(1))\n        f = f[min_index]\n        findx = min_index\n    fout = f[findx]\n    return fout, findx[0]\n\n\ndef dpsschk(tapers, N, Fs):\n    [tapers, eigs] = dpss(N, tapers[0], tapers[1])\n    tapers = np.multiply(tapers, np.sqrt(Fs))\n    return tapers, eigs\n\ndef mtfftc(data, tapers, nfft, Fs):\n    data = change_row_to_column(data)\n    NC, C = data.shape\n    NK, K = tapers.shape\n    if NK != NC:\n        print(\"length of tapers is not compatible with length of data!!\")\n    # tapers=tapers[:,:,np.ones()]\n    # data=data[:,:,ones()]\n    # data=np.transpose(data, (0, 2, 1))\n    data_mat = np.tile(data, (1, K))  # to create the matrix which has n rows X  n1cols\n    data_proj = np.multiply(data_mat, tapers)\n    J = np.fft.fft(data_proj, n=nfft, axis=0) / Fs\n    return J\n\n\ndef mt_spectrogram(data, *args):\n    print('calculate spectr')\n\n    if len(args) == 1:\n        Fs = args[0]\n    elif len(args) == 2:\n        Fs = args[0]\n        params = args[1]\n\n    if 'params' in locals():\n        print('params is defined')\n        pad1 = params.pad1\n        fpass = params.fpass\n        trialave = params.trialave\n        err = params.err\n        movingwin = params.movingwin\n        tapers = params.tapers\n    else:\n        print('params is not defined!!')\n        pad1 = 0\n        fpass = [0, 55]\n        trialave = 0\n        err = 0\n        movingwin = [4, 1]\n        tapers = [3, 5]\n\n        Fs = 200\n        fpass = [0.5, 20]\n        trialve = 0\n        err = 0\n        movingwin = [2, 2]\n        tapers = [2, 3]\n\n    data = change_row_to_column(data)\n    [N, Ch] = data.shape\n    Nwin = round(Fs * movingwin[0])\n    Nstep = round(movingwin[1] * Fs)\n    nextPow2v = nextpow2(Nwin)\n    nfft = max(pow(2, nextPow2v + pad1), Nwin)\n    [sfreqs, findx] = getfgrid(Fs, nfft, fpass)\n    Nf = len(sfreqs)\n    tapersMod = dpsschk(tapers, N, Fs)\n\n    endV = N - Nwin + 1\n    winstart = np.arange(0, endV, Nstep)\n    if winstart[len(winstart) - 1] != endV:\n        winstart = np.append(winstart, endV)\n\n    nw = len(winstart) - 1\n\n    if trialave == 0:\n        S = np.zeros((nw, Nf))\n    else:\n        S = np.zeros((nw, Nf, Ch))\n\n    \"\"\" tapers are calculated only in for first two loopsb \"\"\"\n    for ii in range(0, 2):\n        start = winstart[ii]\n        end = winstart[ii] + Nwin\n        indx = np.arange(start, end)\n        indx = indx.astype(int)\n\n        datawin = signal.detrend(data[indx], type == \"constant\")\n        # datawin = signal.detrend(data[indx])\n        datawin = change_row_to_column(datawin)\n        N = datawin.shape[0]\n        taps = dpsschk(tapers, N, Fs)\n        J = mtfftc(datawin, taps[0], nfft, Fs)\n        J = J[findx, :]\n        s = np.mean((np.multiply(np.conj(J), J)), axis=1).squeeze()\n        if trialave == 1:\n            s = (np.mean(s, axis=1).squeeze())\n        S[ii, :] = s\n\n    for ii in range(2, nw - 1):\n        start = winstart[ii]\n        end = winstart[ii] + Nwin\n        indx = np.arange(start, end)\n        indx = indx.astype(int)\n        datawin = signal.detrend(data[indx], type == \"constant\")\n        # datawin = signal.detrend(data[indx])\n        datawin = change_row_to_column(datawin)\n        N = datawin.shape[0]\n        taps = dpsschk(tapers, N, Fs)\n        J = mtfftc(datawin, taps[0], nfft, Fs)\n        J = J[findx, :]\n        s = np.mean((np.multiply(np.conj(J), J)), axis=1).squeeze()\n        if trialave == 1:\n            s = (np.mean(s, axis=1).squeeze())\n        S[ii, :] = s\n\n    spect = S.squeeze()  # final spectrogram matrix\n\n    winmid = winstart[:-1] + np.round(Nwin / 2)\n    stimes = winmid / Fs  # contains the time stamps\n\n    return spect, stimes, sfreqs\n\n\n\ndef save(fp, d):\n    # print('saveing',fp)\n    # hdf5storage.savemat(fp,d)\n    fp = fp + '.mat'\n    print('Saving to %s' % fp, '| variables;', *['%s' % e for e in d.keys()])\n\n    if os.path.exists(fp):\n        os.remove(fp)\n    for e in d.keys():\n        obj = d[e]\n        print('key', e, 'shape', obj.shape, obj.dtype)\n        print(obj)\n\n        def apply_f(a, f):\n            # if isinstance(a, list):\n            print(str(type(a)))\n            if 'cellarray' in str(type(a)):\n                print('cell')\n                return map(lambda t: apply_f(t, f), a)\n            else:\n                print('other')\n                return f(a)\n\n        out_obj = list(apply_f(obj, lambda e: e.copy()))\n\n        hdf5storage.write(data=out_obj, path='/%s' % e, filename=fp,\n                          store_python_metadata=False, matlab_compatible=True)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from joblib import Parallel, delayed\nimport numpy as np\nfrom numpy.core.defchararray import lower\nfrom scipy.signal import detrend\nimport nitime.algorithms as tsa\n\n#from tsne.func.matlablib.runtime import cell, arange, size, find, matlabarray\n#from tsne.func.matlablib.runtime import cellarray\n\n\ndef step1_load_subtract(fileName0):\n    fp = fileName0\n    with load_mat(fp):\n        matfile = load(fp)\n        Fs = cellarray(matfile['Fs'])\n        start_time = cellarray(matfile['start_time'])\n        # channels = cellarray((51,1))\n        channels = cellarray(matfile['channels'])\n        data = cellarray(matfile['data'])\n\n    \n    # TODO: Resample to 200 Hz!!! %\n    # data = np.resample(data, 200, Fs)\n    # data = data.T\n    # Fs = 200\n\n\n    print('targetFolder', targetFolder)\n    \n    def strrep_s(a, x, y):\n        return a.replace(x, y)\n\n    strrep = np.vectorize(strrep_s)\n\n    print('channels', channels)\n    print(size(channels, 1))\n    # df_s0=pd.DataFrame()\n    labels = copy(channels)\n\n    for i in arange(1, size(channels, 1)).reshape(-1):\n        #     print(i)\n        x = strrep(channels[i, :], ' ', '')\n        labels[i] = lower(x)\n\n\n    disp('load 0')\n    disp('compute 1')\n    # pd=copy(pwd)\n    movingwin = matlabarray(cat(2, 2))\n\n    # dictobj\n    params = Dict2Obj({'default': 1})\n\n    params.pad = copy(0)\n    params.fpass = copy(cat(0.5, 20))\n    params.err = copy(0)\n    params.trialave = copy(0)\n    params.tapers = copy(cat(2, 3))\n    params.Fs = copy(200)\n\n\n    COI = cell(4, )\n    COI[1] = cellarray([['fp1', 'f7'], ['f7', 't3'], ['t3', 't5'], ['t5', 'o1']])\n    COI[2] = cellarray([['fp1', 'f3'], ['f3', 'c3'], ['c3', 'p3'], ['p3', 'o1']])\n    COI[3] = cellarray([['fp2', 'f4'], ['f4', 'c4'], ['c4', 'p4'], ['p4', 'o2']])\n    COI[4] = cellarray([['fp2', 'f8'], ['f8', 't4'], ['t4', 't6'], ['t6', 'o2']])\n\n    print('COI', COI)\n\n    ROInickname = cellarray(['LL', 'LP', 'RP', 'RL'])\n    print(ROInickname)\n\n    # test\n    def strcmp_s(x, y):\n        return x == y\n    strcmp = np.vectorize(strcmp_s)\n\n    dataB = cell(4, 4)\n    for kk in arange(1, 4).reshape(-1):\n        coi = COI[kk]\n\n        for k in arange(1, size(coi, 1)).reshape(-1):\n            print('kk', kk, 'k', k, coi[k, 1], coi[k, 2])\n\n            c1 = find(strcmp(labels, coi[k, 1]))\n            c2 = find(strcmp(labels, coi[k, 2]))\n            c1 = c1.item()\n            c2 = c2.item()\n            print('items', c1, c2)\n            dataB[kk, k] = np.array((data[c1, :] - data[c2, :]).tolist())\n\n    d = {}\n    d['dataB'] = dataB\n    outp = catstr(targetFolder, '/strcmp_', fileName0)\n    save(outp, d)\n    \n    \n    # compute spectrogram for each channel\n    spect = cell(4, 4)\n    disp('compute 2', 'compute spectrogram for each channel')\n    print('params', params.Fs, movingwin)\n\n    for kk in arange(1, 4).reshape(-1):\n        for k in arange(1, 4).reshape(-1):\n            print('kk', kk, 'k', k)\n            s = dataB[kk, k]\n            params.Fs = copy(Fs).item()\n\n            S, stimes, sfreqs = mt_spectrogram(s, Fs)\n\n            spect[kk, k] = np.array(S.T)\n            # Average over this region\n    d = {}\n    d['dataB'] = dataB\n    outp = catstr(targetFolder, '/compute2_', fileName0)\n    save(outp, d)\n    \n    print(spect.shape)\n    \n\nif __name__ == '__main__':\n    #### 1.0 Loading data ####\n\n    # - input -\n    #dataPath = '/Data/'\n    #print('dataPath',dataPath)\n    \n    # - output -\n    targetFolder = catstr('./')\n    \n    fileName0='Case18_seg1.mat'\n    \n    print('Loading',fileName0)\n    \n    step1_load_subtract(fileName0)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "# get_features function\ndef fcn_shannon_entro(x0=None,*args,**kwargs):\n    M,N=size(x0,nargout=2)\n    # y=zeros(1,N)\n    # y=zeros((1,N))\n    x=np.array(x0[:],dtype=complex)\n    y=matlabarray(np.zeros((1,N),dtype=complex))\n    for l in arange(1,N).reshape(-1):\n        # sum1=sum(multiply(x[:,l],log(x[:,l])))\n        sum1 = sum(multiply(x[:], log(x[:])))\n        sum1=dot(-1,sum1)\n        y[1,l]=sum1\n\n    return y\n\n\ndef bandpower(Pxx, f, frange, opt='psd'):\n    \"\"\" integrate the power spectral density between fmin and fmax\n        using the trapezoidal method\n    \"\"\"\n    (fmin, fmax) = frange\n    ind_min = scipy.argmax(f > fmin) - 1\n\n    ind_max = scipy.argmax(f > fmax) + 1\n    print(ind_min, ind_max)\n    return Pxx[ind_min: ind_max].sum(axis=0) * np.diff(f)[0]\n\n\ndef get_features(data=None, i=None, window_length=None, spect=None, sfreqs=None, spectwindow_length=None, Fs=None,\n                 *args, **kwargs):\n    # time features: line length, kurtosis, shannon entropy and nonlinear energy.\n    # spectral features: delta, theta, alpha and beta bandpower. delta to theta\n    # ratio, theta to alpha ratio and delta to alpha ratio. Kurtosis of delta,\n    # theta, alpha and beta bandpower.\n\n    print(\"compute\", i)\n\n    # window_length = [14 10 6 2]*Fs; # the different windows for each segment\n\n    t = dot((i - 1), window_length[4]) + dot(0.5, window_length[1])\n\n    line1avg = 0\n    line2avg = 0\n    line3avg = 0\n    line4avg = 0\n\n    kurt1avg = 0\n    kurt2avg = 0\n    kurt3avg = 0\n    kurt4avg = 0\n\n    shan1avg = 0\n    shan2avg = 0\n    shan3avg = 0\n    shan4avg = 0\n\n    psy1meanavg = 0\n    psy2meanavg = 0\n    psy3meanavg = 0\n    psy4meanavg = 0\n\n    psy1stdavg = 0\n    psy2stdavg = 0\n    psy3stdavg = 0\n    psy4stdavg = 0\n\n    for k in arange(1, 4).reshape(-1):\n        # win1=data[k][arange(t - dot(0.5,window_length[1]) + 1,t + dot(0.5,window_length[1]))]\n        # win2=data[k][arange(t - dot(0.5,window_length[2]) + 1,t + dot(0.5,window_length[2]))]\n        # win3=data[k][arange(t - dot(0.5,window_length[3]) + 1,t + dot(0.5,window_length[3]))]\n        # win4=data[k][arange(t - dot(0.5,window_length[4]) + 1,t + dot(0.5,window_length[4]))]\n        # win1=matlabarray([])\n        win1o = data[k][t - dot(0.5, window_length[1]):t + dot(0.5, window_length[1])]\n        win2o = data[k][t - dot(0.5, window_length[2]):t + dot(0.5, window_length[2])]\n        win3o = data[k][t - dot(0.5, window_length[3]):t + dot(0.5, window_length[3])]\n        win4o = data[k][t - dot(0.5, window_length[4]):t + dot(0.5, window_length[4])]\n\n        win1 = matlabarray(data[k][t - dot(0.5, window_length[1]):t + dot(0.5, window_length[1])])\n        win2 = matlabarray(data[k][t - dot(0.5, window_length[2]):t + dot(0.5, window_length[2])])\n        win3 = matlabarray(data[k][t - dot(0.5, window_length[3]):t + dot(0.5, window_length[3])])\n        win4 = matlabarray(data[k][t - dot(0.5, window_length[4]):t + dot(0.5, window_length[4])])\n\n        # time features\n        line1 = 0\n        line2 = 0\n        line3 = 0\n        line4 = 0\n\n        for j in arange(1, window_length[1] - 1).reshape(-1):\n            line1 = line1 + abs(win1[j + 1] - win1[j])\n\n        line1 = line1 / (window_length[1] - 1)\n\n        for j in arange(1, window_length[2] - 1).reshape(-1):\n            line2 = line2 + abs(win2[j + 1] - win2[j])\n\n        line2 = line2 / (window_length[2] - 1)\n\n        for j in arange(1, window_length[3] - 1).reshape(-1):\n            line3 = line3 + abs(win3[j + 1] - win3[j])\n\n        line3 = line3 / (window_length[3] - 1)\n\n        for j in arange(1, window_length[4] - 1).reshape(-1):\n            line4 = line4 + abs(win4[j + 1] - win4[j])\n\n        line4 = line4 / (window_length[4] - 1)\n\n        kurt1 = kurtosis(win1o, 0)\n        kurt2 = kurtosis(win2o, 0)\n        kurt3 = kurtosis(win3o, 0)\n        kurt4 = kurtosis(win4o, 0)\n\n        #     samp_en1 = fcn_SampEn(2, 0.2*std(win1), win1); # sample entropy\n        #     samp_en2 = fcn_SampEn(2, 0.2*std(win2), win2);\n        #     samp_en3 = fcn_SampEn(2, 0.2*std(win3), win3);\n        #     samp_en4 = fcn_SampEn(2, 0.2*std(win4), win4);\n        shan1 = abs(fcn_shannon_entro(win1.T))\n        shan2 = abs(fcn_shannon_entro(win2.T))\n        shan3 = abs(fcn_shannon_entro(win3.T))\n        shan4 = abs(fcn_shannon_entro(win4.T))\n\n        # psy1=zeros(1,length(win1) - 3)\n        psy1 = matlabarray(np.zeros((1, length(win1) - 3)))\n\n        for n in arange(4, length(win1)).reshape(-1):\n            psy1[n - 3] = dot(win1[n - 1], win1[n - 2]) - dot(win1[n], win1[n - 3])\n\n        psy1mean = mean(abs(psy1))\n        psy1std = std(psy1, ddof=1)\n\n        # psy2=zeros(1,length(win2) - 3)\n        psy2 = matlabarray(np.zeros((1, length(win2) - 3)))\n\n        for n in arange(4, length(win2)).reshape(-1):\n            psy2[n - 3] = dot(win2[n - 1], win2[n - 2]) - dot(win2[n], win2[n - 3])\n\n        psy2mean = mean(abs(psy2))\n        psy2std = std(psy2, ddof=1)\n\n        # psy3=zeros(1,length(win3) - 3)\n        psy3 = matlabarray(np.zeros((1, length(win3) - 3)))\n\n        for n in arange(4, length(win3)).reshape(-1):\n            psy3[n - 3] = dot(win3[n - 1], win3[n - 2]) - dot(win3[n], win3[n - 3])\n\n        psy3mean = mean(abs(psy3))\n        psy3std = std(psy3, ddof=1)\n\n        # psy4=zeros(1,length(win4) - 3)\n        psy4 = matlabarray(np.zeros((1, length(win4) - 3)))\n\n        for n in arange(4, length(win4)).reshape(-1):\n            psy4[n - 3] = dot(win4[n - 1], win4[n - 2]) - dot(win4[n], win4[n - 3])\n\n        psy4mean = mean(abs(psy4))\n        psy4std = std(psy4, ddof=1)\n\n        line1avg = line1avg + line1\n        line2avg = line2avg + line2\n        line3avg = line3avg + line3\n        line4avg = line4avg + line4\n\n        kurt1avg = kurt1avg + kurt1\n        kurt2avg = kurt2avg + kurt2\n        kurt3avg = kurt3avg + kurt3\n        kurt4avg = kurt4avg + kurt4\n\n        shan1avg = shan1avg + shan1\n        shan2avg = shan2avg + shan2\n        shan3avg = shan3avg + shan3\n        shan4avg = shan4avg + shan4\n\n        psy1meanavg = psy1meanavg + psy1mean\n        psy2meanavg = psy2meanavg + psy2mean\n        psy3meanavg = psy3meanavg + psy3mean\n        psy4meanavg = psy4meanavg + psy4mean\n\n        psy1stdavg = psy1stdavg + psy1std\n        psy2stdavg = psy2stdavg + psy2std\n        psy3stdavg = psy3stdavg + psy3std\n        psy4stdavg = psy4stdavg + psy4std\n\n    line1avg = line1avg / 4\n    line2avg = line2avg / 4\n    line3avg = line3avg / 4\n    line4avg = line4avg / 4\n\n    kurt1avg = kurt1avg / 4\n    kurt2avg = kurt2avg / 4\n    kurt3avg = kurt3avg / 4\n    kurt4avg = kurt4avg / 4\n\n    shan1avg = shan1avg / 4\n    shan2avg = shan2avg / 4\n    shan3avg = shan3avg / 4\n    shan4avg = shan4avg / 4\n\n    psy1meanavg = psy1meanavg / 4\n    psy2meanavg = psy2meanavg / 4\n    psy3meanavg = psy3meanavg / 4\n    psy4meanavg = psy4meanavg / 4\n\n    psy1stdavg = psy1stdavg / 4\n    psy2stdavg = psy2stdavg / 4\n    psy3stdavg = psy3stdavg / 4\n    psy4stdavg = psy4stdavg / 4\n\n    # spectral features\n    #### t1 = ceil(t/Fs/2);\n    tt1 = ceil(t / Fs / 2 - dot(0.5, spectwindow_length))\n    tt2 = ceil(t / Fs / 2 + dot(0.5, spectwindow_length))\n    tt1 = tt1.astype(int)\n    tt2 = tt2.astype(int)\n\n    # edit: matrix select---\n    # spectwin1=spect[:,tt1[1] + 1:tt2[1]]\n    # spectwin2=spect[:,tt1[2] + 1:tt2[2]]\n    # spectwin3=spect[:,tt1[3] + 1:tt2[3]]\n    # spectwin4=spect[:,tt1[4] + 1:tt2[4]]\n    spectwin1 = spect[:, tt1[1]:tt2[1]]\n    spectwin2 = spect[:, tt1[2]:tt2[2]]\n    spectwin3 = spect[:, tt1[3]:tt2[3]]\n    spectwin4 = spect[:, tt1[4]:tt2[4]]\n\n    eps = 0.0\n    delta1 = bandpower(spectwin1, sfreqs, cat(1, 4), 'psd')\n    theta1 = bandpower(spectwin1, sfreqs, cat(4, 8), 'psd')\n    alpha1 = bandpower(spectwin1, sfreqs, cat(8, 12), 'psd')\n    beta1 = bandpower(spectwin1, sfreqs, cat(12, 18), 'psd')\n    total1 = bandpower(spectwin1, sfreqs, cat(1, sfreqs[len(sfreqs) - 2]), 'psd') + eps\n    # total1 = bandpower(spectwin1, sfreqs, cat(1, sfreqs[end()]), 'psd')\n\n    delta1_rat = delta1 / total1\n    theta1_rat = theta1 / total1\n    alpha1_rat = alpha1 / total1\n    beta1_rat = beta1 / total1\n\n    delta_theta1 = delta1 / (theta1 + eps)\n    delta_alpha1 = delta1 / (alpha1 + eps)\n    theta_alpha1 = theta1 / (alpha1 + eps)\n\n    kurtdelta1 = kurtosis(delta1, 0)\n    kurttheta1 = kurtosis(theta1, 0)\n    kurtalpha1 = kurtosis(alpha1, 0)\n    kurtbeta1 = kurtosis(beta1, 0)\n\n    delta1_mean = mean(delta1_rat)\n    theta1_mean = mean(theta1_rat)\n    alpha1_mean = mean(alpha1_rat)\n    beta1_mean = mean(beta1_rat)\n\n    delta1_min = min(delta1_rat)\n    theta1_min = min(theta1_rat)\n    alpha1_min = min(alpha1_rat)\n    beta1_min = min(beta1_rat)\n\n    delta1_std = std(delta1_rat)\n    theta1_std = std(theta1_rat)\n    alpha1_std = std(alpha1_rat)\n    beta1_std = std(beta1_rat)\n\n    delta1_prct = prctile(delta1_rat, 95)\n    theta1_prct = prctile(theta1_rat, 95)\n    alpha1_prct = prctile(alpha1_rat, 95)\n    beta1_prct = prctile(beta1_rat, 95)\n\n    delthe1_mean = mean(delta_theta1)\n    delalph1_mean = mean(delta_alpha1)\n    thealph1_mean = mean(theta_alpha1)\n\n    delthe1_min = min(delta_theta1)\n    delalph1_min = min(delta_alpha1)\n    thealph1_min = min(theta_alpha1)\n\n    delthe1_std = std(delta_theta1)\n    delalph1_std = std(delta_alpha1)\n    thealph1_std = std(theta_alpha1)\n\n    delthe1_prct = prctile(delta_theta1, 95)\n    delalph1_prct = prctile(delta_alpha1, 95)\n    thealph1_prct = prctile(theta_alpha1, 95)\n\n    delta2 = bandpower(spectwin2, sfreqs, cat(sfreqs[1], 4), 'psd')\n    theta2 = bandpower(spectwin2, sfreqs, cat(4, 8), 'psd')\n    alpha2 = bandpower(spectwin2, sfreqs, cat(8, 12), 'psd')\n    beta2 = bandpower(spectwin2, sfreqs, cat(12, 18), 'psd')\n    total2 = bandpower(spectwin2, sfreqs, cat(1, sfreqs[len(sfreqs) - 2]), 'psd') + eps\n    # total2=bandpower(spectwin2,sfreqs,'psd') + eps\n    # total2=beta2\n\n    delta2_rat = delta2 / total2\n    theta2_rat = theta2 / total2\n    alpha2_rat = alpha2 / total2\n    beta2_rat = beta2 / total2\n\n    delta_theta2 = delta2 / (theta2 + eps)\n    delta_alpha2 = delta2 / (alpha2 + eps)\n    theta_alpha2 = theta2 / (alpha2 + eps)\n\n    kurtdelta2 = kurtosis(delta2, 0)\n    kurttheta2 = kurtosis(theta2, 0)\n    kurtalpha2 = kurtosis(alpha2, 0)\n    kurtbeta2 = kurtosis(beta2, 0)\n\n    delta2_mean = mean(delta2_rat)\n    theta2_mean = mean(theta2_rat)\n    alpha2_mean = mean(alpha2_rat)\n    beta2_mean = mean(beta2_rat)\n\n    delta2_min = min(delta2_rat)\n    theta2_min = min(theta2_rat)\n    alpha2_min = min(alpha2_rat)\n    beta2_min = min(beta2_rat)\n\n    delta2_std = std(delta2_rat)\n    theta2_std = std(theta2_rat)\n    alpha2_std = std(alpha2_rat)\n    beta2_std = std(beta2_rat)\n\n    delta2_prct = prctile(delta2_rat, 95)\n    theta2_prct = prctile(theta2_rat, 95)\n    alpha2_prct = prctile(alpha2_rat, 95)\n    beta2_prct = prctile(beta2_rat, 95)\n\n    delthe2_mean = mean(delta_theta2)\n    delalph2_mean = mean(delta_alpha2)\n    thealph2_mean = mean(theta_alpha2)\n\n    delthe2_min = min(delta_theta2)\n    delalph2_min = min(delta_alpha2)\n    thealph2_min = min(theta_alpha2)\n\n    delthe2_std = std(delta_theta2)\n    delalph2_std = std(delta_alpha2)\n    thealph2_std = std(theta_alpha2)\n\n    delthe2_prct = prctile(delta_theta2, 95)\n    delalph2_prct = prctile(delta_alpha2, 95)\n    thealph2_prct = prctile(theta_alpha2, 95)\n\n    delta3 = bandpower(spectwin3, sfreqs, cat(sfreqs[1], 4), 'psd')\n    theta3 = bandpower(spectwin3, sfreqs, cat(4, 8), 'psd')\n    alpha3 = bandpower(spectwin3, sfreqs, cat(8, 12), 'psd')\n    beta3 = bandpower(spectwin3, sfreqs, cat(12, 18), 'psd')\n    # total3=bandpower(spectwin3,sfreqs,'psd') + eps\n    total3 = bandpower(spectwin3, sfreqs, cat(1, sfreqs[len(sfreqs) - 2]), 'psd') + eps\n\n    delta3_rat = delta3 / total3\n    theta3_rat = theta3 / total3\n    alpha3_rat = alpha3 / total3\n    beta3_rat = beta3 / total3\n\n    delta_theta3 = delta3 / (theta3 + eps)\n    delta_alpha3 = delta3 / (alpha3 + eps)\n    theta_alpha3 = theta3 / (alpha3 + eps)\n\n    kurtdelta3 = kurtosis(delta3, 0)\n    kurttheta3 = kurtosis(theta3, 0)\n    kurtalpha3 = kurtosis(alpha3, 0)\n    kurtbeta3 = kurtosis(beta3, 0)\n\n    delta3_mean = mean(delta3_rat)\n    theta3_mean = mean(theta3_rat)\n    alpha3_mean = mean(alpha3_rat)\n    beta3_mean = mean(beta3_rat)\n\n    delta3_min = min(delta3_rat)\n    theta3_min = min(theta3_rat)\n    alpha3_min = min(alpha3_rat)\n    beta3_min = min(beta3_rat)\n\n    delta3_std = std(delta3_rat)\n    theta3_std = std(theta3_rat)\n    alpha3_std = std(alpha3_rat)\n    beta3_std = std(beta3_rat)\n\n    delta3_prct = prctile(delta3_rat, 95)\n    theta3_prct = prctile(theta3_rat, 95)\n    alpha3_prct = prctile(alpha3_rat, 95)\n    beta3_prct = prctile(beta3_rat, 95)\n\n    delthe3_mean = mean(delta_theta3)\n    delalph3_mean = mean(delta_alpha3)\n    thealph3_mean = mean(theta_alpha3)\n\n    delthe3_min = min(delta_theta3)\n    delalph3_min = min(delta_alpha3)\n    thealph3_min = min(theta_alpha3)\n\n    delthe3_std = std(delta_theta3)\n    delalph3_std = std(delta_alpha3)\n    thealph3_std = std(theta_alpha3)\n\n    delthe3_prct = prctile(delta_theta3, 95)\n    delalph3_prct = prctile(delta_alpha3, 95)\n    thealph3_prct = prctile(theta_alpha3, 95)\n\n    delta4 = bandpower(spectwin4, sfreqs, cat(sfreqs[1], 4), 'psd')\n    theta4 = bandpower(spectwin4, sfreqs, cat(4, 8), 'psd')\n    alpha4 = bandpower(spectwin4, sfreqs, cat(8, 12), 'psd')\n    beta4 = bandpower(spectwin4, sfreqs, cat(12, 18), 'psd')\n    # total4=bandpower(spectwin4,sfreqs,'psd') + eps\n    total4 = bandpower(spectwin4, sfreqs, cat(1, sfreqs[len(sfreqs) - 2]), 'psd') + eps\n\n    delta4_rat = delta4 / total4\n    theta4_rat = theta4 / total4\n    alpha4_rat = alpha4 / total4\n    beta4_rat = beta4 / total4\n\n    delta_theta4 = delta4 / (theta4 + eps)\n    delta_alpha4 = delta4 / (alpha4 + eps)\n    theta_alpha4 = theta4 / (alpha4 + eps)\n\n    # kurtdelta4 = kurtosis(delta4);\n    # kurttheta4 = kurtosis(theta4);\n    # kurtalpha4 = kurtosis(alpha4);\n    # kurtbeta4 = kurtosis(beta4);\n    delta4_mean = mean(delta4_rat)\n    theta4_mean = mean(theta4_rat)\n    alpha4_mean = mean(alpha4_rat)\n    beta4_mean = mean(beta4_rat)\n\n    delta4_min = min(delta4_rat)\n    theta4_min = min(theta4_rat)\n    alpha4_min = min(alpha4_rat)\n    beta4_min = min(beta4_rat)\n\n    delta4_std = std(delta4_rat)\n    theta4_std = std(theta4_rat)\n    alpha4_std = std(alpha4_rat)\n    beta4_std = std(beta4_rat)\n\n    delta4_prct = prctile(delta4_rat, 95)\n    theta4_prct = prctile(theta4_rat, 95)\n    alpha4_prct = prctile(alpha4_rat, 95)\n    beta4_prct = prctile(beta4_rat, 95)\n\n    delthe4_mean = mean(delta_theta4)\n    delalph4_mean = mean(delta_alpha4)\n    thealph4_mean = mean(theta_alpha4)\n\n    delthe4_min = min(delta_theta4)\n    delalph4_min = min(delta_alpha4)\n    thealph4_min = min(theta_alpha4)\n\n    delthe4_std = std(delta_theta4)\n    delalph4_std = std(delta_alpha4)\n    thealph4_std = std(theta_alpha4)\n\n    delthe4_prct = prctile(delta_theta4, 95)\n    delalph4_prct = prctile(delta_alpha4, 95)\n    thealph4_prct = prctile(theta_alpha4, 95)\n\n    line1avg = line1avg.item()\n    line2avg = line2avg.item()\n    line3avg = line3avg.item()\n    line4avg = line4avg.item()\n    features1 = matlabarray(\n        cat([line1avg], [line2avg], [line3avg], [line4avg], [kurt1avg], [kurt2avg], [kurt3avg], [kurt4avg]))\n    features1a = matlabarray(\n        cat([shan1avg], [shan2avg], [shan3avg], [shan4avg], [psy1meanavg], [psy2meanavg], [psy3meanavg], [psy4meanavg],\n            [psy1stdavg], [psy2stdavg], [psy3stdavg], [psy4stdavg]))\n    features1aa = matlabarray(\n        cat([delta1_mean], [delta2_mean], [delta3_mean], [delta4_mean], [theta1_mean], [theta2_mean], [theta3_mean],\n            [theta4_mean], [alpha1_mean], [alpha2_mean], [alpha3_mean], [alpha4_mean]))\n    features1b = matlabarray(\n        cat([beta1_mean], [beta2_mean], [beta3_mean], [beta4_mean], [delta1_min], [delta2_min], [delta3_min],\n            [theta1_min], [theta2_min], [theta3_min], [alpha1_min], [alpha2_min], [alpha3_min], [beta1_min],\n            [beta2_min], [beta3_min], [delta1_std], [delta2_std], [delta3_std], [theta1_std], [theta2_std],\n            [theta3_std], [alpha1_std], [alpha2_std], [alpha3_std], [beta1_std], [beta2_std], [beta3_std],\n            [delta1_prct], [delta2_prct], [delta3_prct], [theta1_prct], [theta2_prct], [theta3_prct], [alpha1_prct],\n            [alpha2_prct], [alpha3_prct], [beta1_prct], [beta2_prct], [beta3_prct], [delthe1_mean], [delthe2_mean],\n            [delthe3_mean], [delthe4_mean], [delalph1_mean], [delalph2_mean], [delalph3_mean], [delalph4_mean],\n            [thealph1_mean], [thealph2_mean], [thealph3_mean], [thealph4_mean], [delthe1_min], [delthe2_min],\n            [delthe3_min], [delalph1_min], [delalph2_min], [delalph3_min], [thealph1_min], [thealph2_min],\n            [thealph3_min], [delthe1_std], [delthe2_std], [delthe3_std], [delalph1_std], [delalph2_std], [delalph3_std],\n            [thealph1_std], [thealph2_std], [thealph3_std], [delthe1_prct], [delthe2_prct], [delthe3_prct],\n            [delalph1_prct], [delalph2_prct], [delalph3_prct], [thealph1_prct], [thealph2_prct], [thealph3_prct],\n            [kurtdelta1], [kurtdelta2], [kurtdelta3], [kurttheta1], [kurttheta2], [kurttheta3], [kurtalpha1],\n            [kurtalpha2], [kurtalpha3], [kurtbeta1], [kurtbeta2], [kurtbeta3]))\n    features2 = matlabarray(\n        cat([delta4_min], [theta4_min], [alpha4_min], [beta4_min], [delta4_std], [theta4_std], [alpha4_std],\n            [beta4_std], [delta4_prct], [theta4_prct], [alpha4_prct], [beta4_prct], [delthe4_min], [delalph4_min],\n            [thealph4_min], [delthe4_std], [delalph4_std], [thealph4_std], [delthe4_prct], [delalph4_prct],\n            [thealph4_prct]))\n\n    # kurtbeta4];\n    features = matlabarray(cat(features1, features1a, features1aa, features1b, features2))\n    # features=matlabarray(cat([features1],[features2]))\n\n    return features\n\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "#### Full pipeline ###\ndef Step1_computeFeaturesFromRawData(fileName0=None, *args, **kwargs):    \n    fp = fileName0\n    with load_mat(fp):\n        matfile = load(fp)\n        Fs = cellarray(matfile['Fs'])\n        start_time = cellarray(matfile['start_time'])\n        # channels = cellarray((51,1))\n        channels = cellarray(matfile['channels'])\n        data = cellarray(matfile['data'])\n\n    # TODO: Resample to 200 Hz!!! %\n    # data = np.resample(data, 200, Fs)\n    # data = data.T\n    # Fs = 200\n\n\n    print('targetFolder', targetFolder)\n\n    def strrep_s(a, x, y):\n        return a.replace(x, y)\n\n    strrep = np.vectorize(strrep_s)\n\n    print('channels', channels)\n    print(size(channels, 1))\n    labels = copy(channels)\n\n    for i in arange(1, size(channels, 1)).reshape(-1):\n        #     print(i)\n        x = strrep(channels[i, :], ' ', '')\n        labels[i] = lower(x)\n\n\n    disp('load 0')\n    disp('compute 1')\n    # pd=copy(pwd)\n    movingwin = matlabarray(cat(2, 2))\n\n    # dictobj\n    params = Dict2Obj({'default': 1})\n\n    params.pad = copy(0)\n    params.fpass = copy(cat(0.5, 20))\n    params.err = copy(0)\n    params.trialave = copy(0)\n    params.tapers = copy(cat(2, 3))\n    params.Fs = copy(200)\n\n\n    COI = cell(4, )\n    COI[1] = cellarray([['fp1', 'f7'], ['f7', 't3'], ['t3', 't5'], ['t5', 'o1']])\n    COI[2] = cellarray([['fp1', 'f3'], ['f3', 'c3'], ['c3', 'p3'], ['p3', 'o1']])\n    COI[3] = cellarray([['fp2', 'f4'], ['f4', 'c4'], ['c4', 'p4'], ['p4', 'o2']])\n    COI[4] = cellarray([['fp2', 'f8'], ['f8', 't4'], ['t4', 't6'], ['t6', 'o2']])\n\n    print('COI', COI)\n\n    ROInickname = cellarray(['LL', 'LP', 'RP', 'RL'])\n    print(ROInickname)\n\n    # test\n    def strcmp_s(x, y):\n        return x == y\n    strcmp = np.vectorize(strcmp_s)\n\n    dataB = cell(4, 4)\n    for kk in arange(1, 4).reshape(-1):\n        coi = COI[kk]\n\n        for k in arange(1, size(coi, 1)).reshape(-1):\n            print('kk', kk, 'k', k, coi[k, 1], coi[k, 2])\n\n            c1 = find(strcmp(labels, coi[k, 1]))\n            c2 = find(strcmp(labels, coi[k, 2]))\n            c1 = c1.item()\n            c2 = c2.item()\n            print('items', c1, c2)\n            dataB[kk, k] = np.array((data[c1, :] - data[c2, :]).tolist())\n\n    d = {}\n    d['dataB'] = dataB\n    outp = catstr(targetFolder, '/strcmp_', fileName0)\n    save(outp, d)\n\n    # compute spectrogram for each channel\n    spect = cell(4, 4)\n    disp('compute 2', 'compute spectrogram for each channel')\n    print('params', params.Fs, movingwin)\n\n    for kk in arange(1, 4).reshape(-1):\n        for k in arange(1, 4).reshape(-1):\n            print('kk', kk, 'k', k)\n            s = dataB[kk, k]\n            params.Fs = copy(Fs).item()\n\n            S, stimes, sfreqs = mt_spectrogram(s, Fs)\n\n            spect[kk, k] = np.array(S.T)\n            # Average over this region\n    d = {}\n    d['dataB'] = dataB\n    outp = catstr(targetFolder, '/compute2_', fileName0)\n    save(outp, d)\n\n    # compute regional averages\n    disp('compute 3', 'compute regional averages')\n    R = cell(4, 1)\n    for kk in arange(1, 4).reshape(-1):\n        # print('kk',kk,'size',size(spect[kk,1-1]),spect[kk,1-1].shape,tuple(size(spect[kk,1-1])))\n        T = np.zeros(size(spect[kk, 1]))\n        print('T', T)\n        # T = zeros(sizespect[kk, 1 - 1].shape[0])\n        print('T', T.shape)\n        for k in arange(1, 4).reshape(-1):\n            print('kk', kk, 'k', k)\n\n            T = T + spect[kk, k]\n        R[kk] = T / 4\n\n    print('save 0')\n    d = {}\n    d['dataB'] = dataB\n    d['sfreqs'] = sfreqs\n    d['stimes'] = stimes\n    d['Fs'] = Fs\n    d['R'] = R\n    outp = catstr(targetFolder, '/spect_', fileName0)\n    save(outp, d)  # 7.3 by default\n\n    # TODO: test spect_\n\n    #### 1.2 Compute features ####\n    disp('compute 4', 'compute features')\n    Fs = Fs.item()\n    epoch_length = dot(Fs, 2)\n    window_length = dot(cat(14, 10, 6, 2), Fs)\n\n    # filtering of data\n    fnyq = Fs / 2  # nyquist frequency\n    fc_high = 50\n    fc_low = 0.5\n    #  cutoff frequencies\n\n    b, a = butter(6, cat(fc_low / fnyq, fc_high / fnyq), 'bandpass')\n\n    for kk in arange(1, 4).reshape(-1):\n        for k in arange(1, 4).reshape(-1):\n            print('kk', kk, 'k', k)\n            temp = dataB[kk, k]\n\n            dataB[kk, k] = filtfilt(b, a, temp, padtype='odd', padlen=3 * (np.amax((len(a), len(b))) - 1))\n\n    disp('save 1', outp)\n    outp = catstr(targetFolder, '/filtered_data_', fileName0)\n    d = {}\n    d['dataB'] = dataB\n    d['Fs'] = cellarray(Fs)\n    # save(outp, dataB, Fs)\n    save(outp, d)\n    # TODO: Test_filt\n\n    # ------\n\n    disp('compute 5')\n    spectwindow_length = floor(window_length / Fs / 2)\n\n    # fix: per jingjing\n    # nr_epochs=floor(length(dataB[1,1](arange(window_length[1] - epoch_length,end()))) / epoch_length)\n    # N=length(dataB[1,1])\n    # N = length(dataB[1-1, 1-1])\n    # nr_epochs=floor((N - (window_length[1] - epoch_length) - Fs) / epoch_length)\n    # nr_features=144\n\n    N = length(dataB[1, 1])\n    nr_epochs = floor((N - (window_length[1] - epoch_length) - Fs) / epoch_length)\n    nr_features = 144\n\n    # features=zeros(4,nr_features,nr_epochs)\n    features = cell(4, nr_features, nr_epochs)\n    # tic\n    for kk in arange(1, 4).reshape(-1):\n        spect = R[kk, 1]\n\n        data = dataB[kk, :]\n        print('kk', kk)\n\n        i = nr_epochs\n        features[kk, :, i] = get_features(data, int(i.item()), window_length, spect, sfreqs, spectwindow_length, Fs)\n\n        # n_jobs = 1  # number of cpus for parallel computing, -1 is all cpus\n        n_jobs = -1\n        verbose = True  # verbosity in parallel computing\n        res = Parallel(n_jobs=n_jobs, verbose=verbose)(\n            # delayed(compute_spec_each_seg)(eeg[window_start[wi]:window_start[wi] + window_length, :], NW, Fs) for wi in range(window_num)\n            delayed(get_features)(data, int(i.item()), window_length, spect, sfreqs, spectwindow_length, Fs) for i in\n            arange(1, nr_epochs).reshape(-1)\n        )\n\n        print(len(res))\n        for i, rr in enumerate(res):\n            # rr[0][freq_good_ids]\n            features[kk, :, i] = rr[0][i]\n\n    # features=reshape(features,cat(dot(4,nr_features),length(features)))\n    features = features.reshape(cat(dot(4, nr_features), length(features)))\n    features = features.T\n\n    outp = catstr(targetFolder, '/features_', fileName0)\n    disp('save 2')\n    # save(cat(targetFolder,'/features_',fileName0),'features','window_length')\n    d = {}\n    d['features'] = features\n    d['window_length'] = window_length\n    # save(outp, features, window_length)\n    save(outp, d)\n\n    status = 0\n    return status\n\n\n# test\nif __name__ == '__main__':\n    pass\n    # filep=\n    filep=''\n    \n    targetFolder = './'\n    Step1_computeFeaturesFromRawData(fileName0=filep)"
        }, 
        {
            "execution_count": 22, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "class load_mat():\n    def __init__(self, filename, mode='r'):\n        self.filename = filename\n        self.mode = mode\n\n    def __enter__(self):\n        print('open')\n        # self.open_file = open(self.filename, self.mode)\n        return 0\n\n    def __exit__(self, *args):\n        # self.open_file.close()\n        print('close')\n\ndef Step1_computeFeaturesFromRawData_LoadData_ComputeSpectrogram(fileName0=None,*args,**kwargs):\n#def Step1_computeFeaturesFromRawData_LoadData_ComputeSpectrogram(fileName0=None,*args,**kwargs):\n#def Step1_computeFeaturesFromRawData(fileName0=None,*args,**kwargs):\n    dataPath = wdir + '/Data/'\n\n    print('dataPath',dataPath)\n    \n    targetFolder = catstr(wdir, '/Output/')\n    import pandas as pd\n\n    #### 1.1 Compute spectrograms ####\n    \n    fp=dataPath +fileName0\n    with load_mat(fp):\n        matfile = load(fp)\n        Fs=cellarray(matfile['Fs'])\n        start_time = cellarray(matfile['start_time'])\n        # channels = cellarray((51,1))\n        channels=cellarray(matfile['channels'])\n        data = cellarray(matfile['data'])\n\n    print('targetFolder',targetFolder)\n\n    def strrep_s(a,x,y):\n        return a.replace(x,y)\n\n    strrep=np.vectorize(strrep_s)\n\n\n    print('channels',channels)\n    print(size(channels,1))\n    # df_s0=pd.DataFrame()\n    labels=copy(channels)\n    print(labels.shape)\n    # for i in arange(1-1,size(channels,1)-1).reshape(-1):\n    for i in arange(1, size(channels, 1)).reshape(-1):\n        x=strrep(channels[i,:],' ','')\n        labels[i] = lower(x)\n\n    if(1):\n        print('labels',labels)\n        for e in labels:\n            print(e)\n\n\n    disp('load 0')\n    disp('compute 1')\n    # pd=copy(pwd)\n    movingwin=matlabarray(cat(2,2))\n\n    # dictobj\n    params=Dict2Obj({'default':1})\n\n    params.pad = copy(0)\n    params.fpass = copy(cat(0.5,20))\n    params.err = copy(0)\n    params.trialave = copy(0)\n    params.tapers = copy(cat(2,3))\n    params.Fs = copy(200)\n\n    # spect=cell(4,4)\n    # COI=numpy.empty((4, ), dtype=object)\n    COI=cell(4,)\n    COI[1]=cellarray([['fp1','f7'],['f7','t3'],['t3','t5'],['t5','o1']])\n    COI[2]=cellarray([['fp1','f3'],['f3','c3'],['c3','p3'],['p3','o1']])\n    COI[3]=cellarray([['fp2','f4'],['f4','c4'],['c4','p4'],['p4','o2']])\n    COI[4]=cellarray([['fp2','f8'],['f8','t4'],['t4','t6'],['t6','o2']])\n\n    print('COI',COI)\n    \n    ROInickname=cellarray(['LL','LP','RP','RL'])\n    print(ROInickname)\n\n\n    # test\n    def strcmp_s(x,y):\n        return x == y\n        \n    strcmp=np.vectorize(strcmp_s)\n\n    dataB=cell(4,4)\n    for kk in arange(1 , 4 ).reshape(-1):\n        # print('kk',kk)\n        coi=COI[kk]\n        print('coi',coi,size(coi,1),size(coi,2),size(coi))\n\n        # for k in arange(1-1,size(coi,1-1)-1).reshape(-1):\n        for k in arange(1 , size(coi, 1) ).reshape(-1):\n            print('kk',kk,'k',k , coi[k,1],coi[k,2])\n\n            c1=find(strcmp(labels,coi[k,1]))\n            c2=find(strcmp(labels,coi[k,2]))\n            c1=c1.item()\n            c2 = c2.item()\n            dataB[kk, k] = np.array((data[c1, :] - data[c2, :]).tolist())\n            \n            \n\n    spect = cell(4,4)\n    disp('compute 2','compute spectrogram for each channel')\n    print('params',params.Fs,movingwin)\n\n    for kk in arange(1,4).reshape(-1):\n        for k in arange(1,4).reshape(-1):\n            print('kk',kk,'k',k)\n            s=dataB[kk,k]\n            params.Fs = copy(Fs).item()\n\n\n            # S,stimes,sfreqs=mtspecgram_mbw(s,params,movingwin,1,nargout=3)\n\n            # S, stimes, sfreqs = mtspecgram(s, params, movingwin)\n            S, stimes, sfreqs = mt_spectrogram(s, Fs)\n\n            print(S,S.T)\n            # spect[kk,k]=S.T\n            spect[kk, k] = np.array(S.T)\n        # Average over this region\n    d={}\n    d['dataB']=dataB\n    outp=catstr(targetFolder, '/compute2_', fileName0)\n    save(outp, d)\n\n\n\n    # compute regional averages\n    disp('compute 3','compute regional averages')\n    # R=cell(4,1)\n    R=cell(4,1)\n    for kk in arange(1,4).reshape(-1):\n        # print('kk',kk,'size',size(spect[kk,1-1]),spect[kk,1-1].shape,tuple(size(spect[kk,1-1])))\n        T=np.zeros(size(spect[kk,1]))\n        print('T',T)\n        # T = zeros(sizespect[kk, 1 - 1].shape[0])\n        print('T',T.shape)\n        for k in arange(1,4).reshape(-1):\n            print('kk',kk,'k',k)\n\n            T=T + spect[kk,k]\n        R[kk]=T / 4\n    "
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2 with Spark 2.0", 
            "name": "python2-spark20", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "2.7.11", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython2", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}
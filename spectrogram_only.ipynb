{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": 43, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "(1, 1)\n(2, 2)\n(3, 3)\n(4, 4)\n(1, 1)\n(1, 2)\n(1, 3)\n(1, 4)\n(2, 1)\n(2, 2)\n(2, 3)\n(2, 4)\n(3, 1)\n(3, 2)\n(3, 3)\n(3, 4)\n(4, 1)\n(4, 2)\n(4, 3)\n(4, 4)\n"
                }
            ], 
            "source": "for e1, e2 in zip([1,2,3,4], [1,2,3,4]):\n                   print(e1,e2)\n        \nl=[(x, y) for x in [1,2,3,4] for y in [1,2,3,4]]\nfor e in l:\n    print(e)\n"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "('Loading', 'Case5/Case5_seg4.mat')\nopen\nclose\n('data', (32, 9999999), array([[ 255.99775]]), array([[u'01-30-2012 22:28:28']], \n      dtype='<U19'), array([[u'C3  '],\n       [u'C4  '],\n       [u'CZ  '],\n       [u'F3  '],\n       [u'F4  '],\n       [u'F7  '],\n       [u'F8  '],\n       [u'FZ  '],\n       [u'FP1 '],\n       [u'FP2 '],\n       [u'FPZ '],\n       [u'O1  '],\n       [u'O2  '],\n       [u'P3  '],\n       [u'P4  '],\n       [u'PZ  '],\n       [u'T3  '],\n       [u'T4  '],\n       [u'T5  '],\n       [u'T6  '],\n       [u'AUX1'],\n       [u'EKG '],\n       [u'CII '],\n       [u'AUX4'],\n       [u'AUX5'],\n       [u'LOC '],\n       [u'ROC '],\n       [u'AUX8'],\n       [u'T1  '],\n       [u'T2  '],\n       [u'A1  '],\n       [u'A2  ']], \n      dtype='<U4'))\n(9999999,)\n24999 windows\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\n110\n120\n130\n140\n150\n160\n170\n180\n190\n200\n210\n220\n230\n240\n250\n260\n270\n280\n290\n300\n310\n320\n330\n340\n350\n360\n370\n380\n390\n400\n410\n420\n430\n440\n450\n460\n470\n480\n490\n500\n510\n520\n530\n540\n550\n560\n570\n580\n590\n600\n610\n620\n630\n640\n650\n660\n670\n680\n690\n700\n710\n720\n730\n740\n750\n760\n770\n780\n790\n800\n810\n820\n830\n840\n850\n860\n870\n880\n890\n900\n910\n920\n930\n940\n950\n960\n970\n980\n990\n1000\n1010\n1020\n1030\n1040\n1050\n1060\n1070\n1080\n1090\n1100\n1110\n1120\n1130\n1140\n1150\n1160\n1170\n1180\n1190\n1200\n1210\n1220\n1230\n1240\n1250\n1260\n1270\n1280\n1290\n1300\n1310\n1320\n1330\n1340\n1350\n1360\n1370\n1380\n1390\n1400\n1410\n1420\n1430\n1440\n1450\n1460\n1470\n1480\n1490\n1500\n1510\n1520\n1530\n1540\n1550\n1560\n1570\n1580\n1590\n1600\n1610\n1620\n1630\n1640\n1650\n1660\n1670\n1680\n1690\n1700\n1710\n1720\n1730\n1740\n1750\n1760\n1770\n1780\n1790\n1800\n1810\n1820\n1830\n1840\n1850\n1860\n1870\n1880\n1890\n1900\n1910\n1920\n1930\n1940\n1950\n1960\n1970\n1980\n1990\n2000\n2010\n2020\n2030\n2040\n2050\n2060\n2070\n2080\n2090\n2100\n2110\n2120\n2130\n2140\n2150\n2160\n2170\n2180\n2190\n2200\n2210\n2220\n2230\n2240\n2250\n2260\n2270\n2280\n2290\n2300\n2310\n2320\n2330\n2340\n2350\n2360\n2370\n2380\n2390\n2400\n2410\n2420\n2430\n2440\n2450\n2460\n2470\n2480\n2490\n2500\n2510\n2520\n2530\n2540\n2550\n2560\n2570\n2580\n2590\n2600\n2610\n2620\n2630\n2640\n2650\n2660\n2670\n2680\n2690\n2700\n2710\n2720\n2730\n2740\n2750\n2760\n2770\n2780\n2790\n2800\n2810\n2820\n2830\n2840\n2850\n2860\n2870\n2880\n2890\n2900\n2910\n2920\n2930\n2940\n2950\n2960\n2970\n2980\n2990\n3000\n3010\n3020\n3030\n3040\n3050\n3060\n3070\n3080\n3090\n3100\n3110\n3120\n3130\n3140\n3150\n3160\n3170\n3180\n3190\n3200\n3210\n3220\n3230\n3240\n3250\n3260\n3270\n3280\n3290\n3300\n3310\n3320\n3330\n3340\n3350\n3360\n3370\n3380\n3390\n3400\n3410\n3420\n3430\n3440\n3450\n3460\n3470\n3480\n3490\n3500\n3510\n3520\n3530\n3540\n3550\n3560\n3570\n3580\n3590\n3600\n3610\n3620\n3630\n3640\n3650\n3660\n3670\n3680\n3690\n3700\n3710\n3720\n3730\n3740\n3750\n3760\n3770\n3780\n3790\n3800\n3810\n3820\n3830\n3840\n3850\n3860\n3870\n3880\n3890\n3900\n3910\n3920\n3930\n3940\n3950\n3960\n3970\n3980\n3990\n4000\n4010\n4020\n4030\n4040\n4050\n4060\n4070\n4080\n4090\n4100\n4110\n4120\n4130\n4140\n4150\n4160\n4170\n4180\n4190\n4200\n4210\n4220\n4230\n4240\n4250\n4260\n4270\n4280\n4290\n4300\n4310\n4320\n4330\n4340\n4350\n4360\n4370\n4380\n4390\n4400\n4410\n4420\n4430\n4440\n4450\n4460\n4470\n4480\n4490\n4500\n4510\n4520\n4530\n4540\n4550\n4560\n4570\n4580\n4590\n4600\n4610\n4620\n4630\n4640\n4650\n4660\n4670\n4680\n4690\n4700\n4710\n4720\n4730\n4740\n4750\n4760\n4770\n4780\n4790\n4800\n4810\n4820\n4830\n4840\n4850\n4860\n4870\n4880\n4890\n4900\n4910\n4920\n4930\n4940\n4950\n4960\n4970\n4980\n4990\n5000\n5010\n5020\n5030\n5040\n5050\n5060\n5070\n5080\n5090\n5100\n5110\n5120\n5130\n5140\n5150\n5160\n5170\n5180\n5190\n5200\n5210\n5220\n5230\n5240\n5250\n5260\n5270\n5280\n5290\n5300\n5310\n5320\n5330\n5340\n5350\n5360\n5370\n5380\n5390\n5400\n5410\n5420\n5430\n5440\n5450\n5460\n5470\n5480\n5490\n5500\n5510\n5520\n5530\n5540\n5550\n5560\n5570\n5580\n5590\n5600\n5610\n5620\n5630\n5640\n5650\n5660\n5670\n5680\n5690\n5700\n5710\n5720\n5730\n5740\n5750\n5760\n5770\n5780\n5790\n5800\n5810\n5820\n5830\n5840\n5850\n5860\n5870\n5880\n5890\n5900\n5910\n5920\n5930\n5940\n5950\n5960\n5970\n5980\n5990\n6000\n6010\n6020\n6030\n6040\n6050\n6060\n6070\n6080\n6090\n6100\n6110\n6120\n6130\n6140\n6150\n6160\n6170\n6180\n6190\n6200\n6210\n6220\n6230\n6240\n6250\n6260\n6270\n6280\n6290\n6300\n6310\n6320\n6330\n6340\n6350\n6360\n6370\n6380\n6390\n6400\n6410\n6420\n6430\n6440\n6450\n6460\n6470\n6480\n6490\n6500\n6510\n6520\n6530\n6540\n6550\n6560\n6570\n6580\n6590\n6600\n6610\n6620\n6630\n6640\n6650\n6660\n6670\n6680\n6690\n6700\n6710\n6720\n6730\n6740\n6750\n6760\n6770\n6780\n6790\n6800\n6810\n6820\n6830\n6840\n6850\n6860\n6870\n6880\n6890\n6900\n6910\n6920\n6930\n6940\n6950\n6960\n6970\n6980\n6990\n7000\n7010\n7020\n7030\n7040\n7050\n7060\n7070\n7080\n7090\n7100\n7110\n7120\n7130\n7140\n7150\n7160\n7170\n7180\n7190\n7200\n7210\n7220\n7230\n7240\n7250\n7260\n7270\n7280\n7290\n7300\n7310\n7320\n7330\n7340\n7350\n7360\n7370\n7380\n7390\n7400\n7410\n7420\n7430\n7440\n7450\n7460\n7470\n7480\n7490\n7500\n7510\n7520\n7530\n7540\n7550\n7560\n7570\n7580\n7590\n7600\n7610\n7620\n7630\n7640\n7650\n7660\n7670\n7680\n7690\n7700\n7710\n7720\n7730\n7740\n7750\n7760\n7770\n7780\n7790\n7800\n7810\n7820\n7830\n7840\n7850\n7860\n7870\n7880\n7890\n7900\n7910\n7920\n7930\n7940\n7950\n7960\n7970\n7980\n7990\n8000\n8010\n8020\n8030\n8040\n8050\n8060\n8070\n8080\n8090\n8100\n8110\n8120\n8130\n8140\n8150\n8160\n8170\n8180\n8190\n8200\n8210\n8220\n8230\n8240\n8250\n8260\n8270\n8280\n8290\n8300\n8310\n8320\n8330\n8340\n8350\n8360\n8370\n8380\n8390\n8400\n8620\n8630\n8640\n8650\n8660\n8670\n8680\n8690\n8700\n8710\n8720\n8730\n8740\n8750\n8760\n8770\n8780\n8790\n8800\n8810\n8820\n8830\n8840\n8850\n8860\n8870\n8880\n8890\n8900\n8910\n8920\n8930\n8940\n8950\n8960\n8970\n8980\n8990\n9000\n9010\n9020\n9030\n9040\n9050\n9060\n9070\n9080\n9090\n9100\n9110\n9120\n9130\n9140\n9150\n9160\n9170\n9180\n9430\n9440\n9450\n9460\n9470\n9480\n9490\n9500\n9510\n9520\n9530\n9540\n9550\n9560\n9570\n9580\n9590\n9600\n9610\n9620\n9630\n9640\n9650\n9660\n9670\n9680\n9690\n9700\n9710\n9720\n9730\n9740\n9750\n9760\n9770\n9780\n9790\n9800\n9810\n9820\n9830\n9840\n9850\n9860\n9870\n9880\n9890\n9900\n9910\n9920\n9930\n9940\n9950\n9960\n9970\n9980\n9990\n10000\n10010\n10020\n10030\n10040\n10050\n10060\n10070\n10080\n10090\n10100\n10110\n10120\n10130\n10140\n10150\n10160\n10170\n10180\n10190\n10200\n10210\n10220\n10230\n10240\n10250\n10260\n10270\n10280\n10290\n10300\n10310\n10320\n10330\n10340\n10350\n10360\n10370\n10380\n10390\n10400\n10410\n10420\n10430\n10440\n10450\n10460\n10470\n10480\n10490\n10500\n10510\n10520\n10530\n10540\n10550\n10560\n10570\n10580\n10590\n10600\n10610\n10620\n10630\n10640\n10650\n10660\n10670\n10680\n10690\n10700\n10710\n10720\n10730\n10740\n10750\n10760\n10770\n10780\n10790\n10800\n10810\n10820\n10830\n10840\n10850\n10860\n10870\n10880\n10890\n10900\n10910\n10920\n10930\n10940\n10950\n10960\n10970\n10980\n10990\n11000\n11010\n11020\n11030\n11040\n11050\n11060\n11070\n11080\n11090\n11100\n11110\n11120\n11130\n11140\n11150\n11160\n11170\n11180\n11190\n11200\n11210\n11220\n11230\n11240\n11250\n11260\n11270\n11280\n11290\n11300\n11310\n11320\n11330\n11340\n11350\n11360\n11370\n11380\n11390\n11400\n11410\n11420\n11430\n11440\n11450\n11460\n11470\n11480\n11490\n11500\n11510\n11520\n11530\n11540\n11550\n11560\n11570\n11580\n11590\n11600\n11610\n11620\n11630\n11640\n11650\n11660\n11670\n11680\n11690\n11700\n11710\n11720\n11730\n11740\n11750\n11760\n11770\n11780\n11790\n11800\n11810\n11820\n11830\n11840\n11850\n11860\n11870\n11880\n11890\n11900\n11910\n11920\n11930\n11940\n11950\n11960\n11970\n11980\n11990\n12000\n12010\n12020\n12030\n12040\n12050\n12060\n12070\n12080\n12090\n12100\n12110\n12120\n12130\n12140\n12150\n12160\n12170\n12180\n12190\n12200\n12210\n12220\n12230\n12240\n12250\n12260\n12270\n12280\n12290\n12300\n12310\n12320\n12330\n12340\n12350\n12360\n12370\n12380\n12390\n12400\n12410\n12420\n12430\n12440\n12450\n12460\n12470\n12480\n12490\n12500\n12510\n12520\n12530\n12540\n12550\n12560\n12570\n12580\n12590\n12600\n12610\n12620\n12630\n12640\n12650\n12660\n12670\n12680\n12690\n12700\n12710\n12720\n12730\n12740\n12750\n12760\n12770\n12780\n12790\n12800\n12810\n12820\n12830\n12840\n12850\n12860\n12870\n12880\n12890\n12900\n12910\n12920\n12930\n12940\n12950\n12960\n12970\n12980\n12990\n13000\n13010\n13020\n13030\n13040\n13050\n13060\n13070\n13080\n13090\n13100\n13110\n13120\n13130\n13140\n13150\n13160\n13170\n13180\n13190\n13200\n13210\n13220\n13230\n13240\n13250\n13260\n13270\n13280\n13290\n13300\n13310\n13320\n13330\n13340\n13350\n13360\n13370\n13380\n13390\n13400\n13410\n13420\n13430\n13440\n13450\n13460\n13470\n13480\n13490\n13500\n13510\n13520\n13530\n13540\n13550\n13560\n13570\n13580\n13590\n13600\n13610\n13620\n13630\n13640\n13650\n13660\n13670\n13680\n13690\n13700\n13710\n13720\n13730\n13740\n13750\n13760\n13770\n13780\n13790\n13800\n13810\n13820\n13830\n13840\n13850\n13860\n13870\n13880\n13890\n13900\n13910\n13920\n13930\n13940\n13950\n13960\n13970\n13980\n13990\n14000\n14010\n14020\n14030\n14040\n14050\n14060\n14070\n14080\n14090\n14100\n14110\n14120\n14130\n14140\n14150\n14160\n14170\n14180\n14190\n14200\n14210\n14220\n14230\n14240\n14250\n14260\n14270\n14280\n14290\n14300\n14310\n14320\n14330\n14340\n14350\n14360\n14370\n14380\n14390\n14400\n14410\n14420\n14430\n14440\n14450\n14460\n14470\n14480\n14490\n14500\n14510\n14520\n14530\n14540\n14550\n14560\n14570\n14580\n14590\n14600\n14610\n14620\n14630\n14640\n14650\n14660\n14670\n14680\n14690\n14700\n14710\n14720\n14730\n14740\n14750\n14760\n14770\n14780\n14790\n14800\n14810\n14820\n14830\n14840\n14850\n14860\n14870\n14880\n14890\n14900\n14910\n14920\n14930\n14940\n14950\n14960\n14970\n14980\n14990\n15000\n15010\n15020\n15030\n15040\n15050\n15060\n15070\n15080\n15090\n15100\n15110\n15120\n15130\n15140\n15150\n15160\n15170\n15180\n15190\n15200\n15210\n15220\n15230\n15240\n15250\n15260\n15270\n15280\n15290\n15300\n15310\n15320\n15330\n15340\n15350\n15360\n15370\n15380\n15390\n15400\n15410\n15420\n15430\n15440\n15450\n15460\n15470\n15480\n15490\n15500\n15510\n15520\n15530\n15540\n15550\n15560\n15570\n15580\n15590\n15600\n15610\n15620\n15630\n15640\n15650\n15660\n15670\n15680\n15690\n15700\n15710\n15720\n15730\n15740\n15750\n15760\n15770\n15780\n15790\n15800\n15810\n15820\n15830\n15840\n15850\n15860\n15870\n15880\n15890\n15900\n15910\n15920\n15930\n15940\n15950\n15960\n15970\n15980\n15990\n16000\n16010\n16020\n16030\n16040\n16050\n16060\n16070\n16080\n16090\n16100\n16110\n16120\n16130\n16140\n16150\n16160\n16170\n16180\n16190\n16200\n16210\n16220\n16230\n16240\n16250\n16260\n16270\n16280\n16290\n16300\n16310\n16320\n16330\n16340\n16350\n16360\n16370\n16380\n16390\n16400\n16410\n16420\n16430\n16440\n16450\n16460\n16470\n16480\n16490\n16500\n16510\n16520\n16530\n16540\n16550\n16560\n16570\n16580\n16590\n16600\n16610\n16620\n16630\n16640\n16650\n16660\n16670\n16680\n16690\n16700\n16710\n16720\n16730\n16740\n16750\n16760\n16770\n16780\n16790\n16800\n16810\n16820\n16830\n16840\n16850\n16860\n16870\n16880\n16890\n16900\n16910\n16920\n16930\n16940\n16950\n16960\n16970\n16980\n16990\n17000\n17010\n17020\n17030\n17040\n17050\n17060\n17070\n17080\n17090\n17100\n17110\n17120\n17130\n17140\n17150\n17160\n17170\n17180\n17190\n17200\n17210\n17220\n17230\n17240\n17250\n17260\n17270\n17280\n17290\n17300\n17310\n17320\n17330\n17340\n17350\n17360\n17370\n17380\n17390\n17400\n17410\n17420\n17430\n17440\n17450\n17460\n17470\n17480\n17490\n17500\n17510\n17520\n17530\n17540\n17550\n17560\n17570\n17580\n17590\n17600\n17610\n17620\n17630\n17640\n17650\n17660\n17670\n17680\n17690\n17700\n17710\n17720\n17730\n17740\n17750\n17760\n17770\n17780\n17790\n17800\n17810\n17820\n17830\n17840\n17850\n17860\n17870\n17880\n17890\n17900\n17910\n17920\n17930\n17940\n17950\n17960\n17970\n17980\n17990\n18000\n18010\n18020\n18030\n18040\n18050\n18060\n18070\n18080\n18090\n18100\n18110\n18120\n18130\n18140\n18150\n18160\n18170\n18180\n18190\n18200\n18210\n18220\n18230\n18240\n18250\n18260\n18270\n18280\n18290\n18300\n18310\n18320\n18330\n18340\n18350\n18360\n18370\n18380\n18390\n18400\n18410\n18420\n18430\n18440\n18450\n18460\n18470\n18480\n18490\n18500\n18510\n18520\n18530\n18540\n18550\n18560\n18570\n18580\n18590\n18600\n18610\n18620\n18630\n18640\n18650\n18660\n18670\n18680\n18690\n18700\n18710\n18720\n18730\n18740\n18750\n18760\n18770\n18780\n18790\n18800\n18810\n18820\n18830\n18840\n18850\n18860\n18870\n18880\n18890\n18900\n18910\n18920\n18930\n18940\n18950\n18960\n18970\n18980\n18990\n19000\n19010\n19020\n19030\n19040\n19050\n19060\n19070\n19080\n19090\n19100\n19110\n19120\n19130\n19140\n19150\n19160\n19170\n19180\n19190\n19200\n19210\n19220\n19230\n19240\n19250\n19260\n19270\n19280\n19290\n19300\n19310\n19320\n19330\n19340\n19350\n19360\n19370\n19380\n19390\n19400\n19410\n19420\n19430\n19440\n19450\n19460\n19470\n19480\n19490\n19500\n19510\n19520\n19530\n19540\n19550\n19560\n19570\n19580\n19590\n19600\n19610\n19620\n19630\n19640\n19650\n19660\n19670\n19680\n19690\n19700\n19710\n19720\n19730\n19740\n19750\n19760\n19770\n19780\n19790\n19800\n19810\n19820\n19830\n19840\n19850\n19860\n19870\n19880\n19890\n19900\n19910\n19920\n19930\n19940\n19950\n19960\n19970\n19980\n19990\n20000\n20010\n20020\n20030\n20040\n20050\n20060\n20070\n20080\n20090\n20100\n20110\n20120\n20130\n20140\n20150\n20160\n20170\n20180\n20190\n20200\n20210\n20220\n20230\n20240\n20250\n20260\n20270\n20280\n20290\n20300\n20310\n20320\n20330\n20340\n20350\n20360\n20370\n20380\n20390\n20400\n20410\n20420\n20430\n20440\n20450\n20460\n20470\n20480\n20490\n20500\n20510\n20520\n20530\n20540\n20550\n20560\n20570\n20580\n20590\n20600\n20610\n20620\n20630\n20640\n20650\n20660\n20670\n20680\n20690\n20700\n20710\n20720\n20730\n20740\n20750\n20760\n20770\n20780\n20790\n20800\n20810\n20820\n20830\n20840\n20850\n20860\n20870\n20880\n20890\n20900\n20910\n20920\n20930\n20940\n20950\n20960\n20970\n20980\n20990\n21000\n21010\n21020\n21030\n21040\n21050\n21060\n21070\n21080\n21090\n21100\n21110\n21120\n21130\n21140\n21150\n21160\n21170\n21180\n21190\n21200\n21210\n21220\n21230\n21240\n21250\n21260\n21270\n21280\n21290\n21300\n21310\n21320\n21330\n21340\n21350\n21360\n21370\n21380\n21390\n21400\n21410\n21420\n21430\n21440\n21450\n21460\n21470\n21480\n21490\n21500\n21510\n21520\n21530\n21540\n21550\n21560\n21570\n21580\n21590\n21600\n21610\n21620\n21630\n21640\n21650\n21660\n21670\n21680\n21690\n21700\n21710\n21720\n21730\n21740\n21750\n21760\n21770\n21780\n21790\n21800\n21810\n21820\n21830\n21840\n21850\n21860\n21870\n21880\n21890\n21900\n21910\n21920\n21930\n21940\n21950\n21960\n21970\n21980\n21990\n22000\n22010\n22020\n22030\n22040\n22050\n22060\n22070\n22080\n22090\n22100\n22110\n22120\n22130\n22140\n22150\n22160\n22170\n22180\n22190\n22200\n22210\n22220\n22230\n22240\n22250\n22260\n22270\n22280\n22290\n22300\n22310\n22320\n22330\n22340\n22350\n22360\n22370\n22380\n22390\n22400\n22410\n22420\n22430\n22440\n22450\n22460\n22470\n22480\n22490\n22500\n22510\n22520\n22530\n22540\n22550\n22560\n22570\n22580\n22590\n22600\n22610\n22620\n22630\n22640\n22650\n22660\n22670\n22680\n22690\n22700\n22710\n22720\n22730\n22740\n22750\n22760\n22770\n22780\n22790\n22800\n22810\n22820\n22830\n22840\n22850\n22860\n22870\n22880\n22890\n22900\n22910\n22920\n22930\n22940\n22950\n22960\n22970\n22980\n22990\n23000\n23010\n23020\n23030\n23040\n23050\n23060\n23070\n23080\n23090\n23100\n23110\n23120\n23130\n23140\n23150\n23160\n23170\n23180\n23190\n23200\n23210\n23220\n23230\n23240\n23250\n23260\n23270\n23280\n23290\n23300\n23310\n23320\n23330\n23340\n23350\n23360\n23370\n23380\n23390\n23400\n23410\n23420\n23430\n23440\n23450\n23460\n23470\n23480\n23490\n23500\n23510\n23520\n23530\n23540\n23550\n23560\n23570\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/gpfs/fs01/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages/nitime/utils.py:571: RuntimeWarning: Breaking due to iterative meltdown in nitime.utils.adaptive_weights.\n  warnings.warn(e_s, RuntimeWarning)\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "23580\n23590\n23600\n23610\n23620\n23630\n23640\n23650\n23660\n23670\n23680\n23690\n23700\n23710\n23720\n23730\n23740\n23750\n23760\n23770\n23780\n23790\n23800\n23810\n23820\n23830\n23840\n23850\n23860\n23870\n23880\n23890\n23900\n23910\n23920\n23930\n23940\n23950\n23960\n23970\n23980\n23990\n24000\n24010\n24020\n24030\n24040\n24050\n24060\n24070\n24080\n24090\n24100\n24110\n24120\n24130\n24140\n24150\n24160\n24170\n24180\n24190\n24200\n24210\n24220\n24230\n24240\n24250\n24260\n24270\n24280\n24290\n24300\n24310\n24320\n24330\n24340\n24350\n24360\n24370\n24380\n24390\n24400\n24410\n24420\n24430\n24440\n24450\n24460\n24470\n24480\n24490\n24500\n24510\n24520\n24530\n24540\n24550\n24560\n24570\n24580\n24590\n24600\n24610\n24620\n24630\n24640\n24650\n24660\n24670\n24680\n24690\n24700\n24710\n24720\n24730\n24740\n24750\n24760\n24770\n24780\n24790\n24800\n24810\n24820\n24830\n24840\n24850\n24860\n24870\n24880\n24890\n24900\n24910\n24920\n24930\n24940\n24950\n24960\n24970\n24980\n24990\n('spect', (24999, 50, 1), array([[[  7.19973528e+01],\n        [  7.75632802e+01],\n        [  4.04923230e+01],\n        ..., \n        [  7.99193389e-03],\n        [  3.08845706e-03],\n        [  8.32566532e-03]],\n\n       [[  3.79903121e+01],\n        [  3.91633539e+01],\n        [  1.84547662e+01],\n        ..., \n        [  1.30509928e-01],\n        [  1.49498020e-01],\n        [  1.48686492e-01]],\n\n       [[  6.06321610e+01],\n        [  6.30417512e+01],\n        [  4.93462877e+01],\n        ..., \n        [  6.61574978e-02],\n        [  7.50933758e-02],\n        [  7.13539451e-02]],\n\n       ..., \n       [[  6.52751661e+01],\n        [  8.55447908e+01],\n        [  1.10587356e+02],\n        ..., \n        [  3.48657079e-01],\n        [  2.65747602e-01],\n        [  2.31941132e-01]],\n\n       [[  2.28810306e+01],\n        [  2.65706045e+01],\n        [  2.71934988e+01],\n        ..., \n        [  1.74042355e-01],\n        [  2.00904037e-01],\n        [  1.89599037e-01]],\n\n       [[  1.62104183e+01],\n        [  1.61670128e+01],\n        [  1.52010124e+01],\n        ..., \n        [  8.18921505e-02],\n        [  5.68865618e-02],\n        [  5.52972540e-02]]]))\n('stimes', (24999,), array([  0.00000000e+00,   2.00000000e+00,   4.00000000e+00, ...,\n         4.99920000e+04,   4.99940000e+04,   4.99960000e+04]))\n('sfreqs', (50,), array([  0.78125 ,   1.171875,   1.5625  ,   1.953125,   2.34375 ,\n         2.734375,   3.125   ,   3.515625,   3.90625 ,   4.296875,\n         4.6875  ,   5.078125,   5.46875 ,   5.859375,   6.25    ,\n         6.640625,   7.03125 ,   7.421875,   7.8125  ,   8.203125,\n         8.59375 ,   8.984375,   9.375   ,   9.765625,  10.15625 ,\n        10.546875,  10.9375  ,  11.328125,  11.71875 ,  12.109375,\n        12.5     ,  12.890625,  13.28125 ,  13.671875,  14.0625  ,\n        14.453125,  14.84375 ,  15.234375,  15.625   ,  16.015625,\n        16.40625 ,  16.796875,  17.1875  ,  17.578125,  17.96875 ,\n        18.359375,  18.75    ,  19.140625,  19.53125 ,  19.921875]))\n"
                }
            ], 
            "source": "### Compute Spectrogram\n\nimport hdf5storage\nfrom joblib import Parallel, delayed\nimport numpy as np\nfrom scipy.signal import detrend\nimport nitime.algorithms as tsa\n\ndef compute_spec_each_seg(eeg_seg, NW, Fs):\n    \"\"\"\n    Input:\n    eeg_seg: numpy.array (point_num x channel_num)\n    NW: Time-halfbandwidth product, 2 or 3 or 4 or ... #taper = 2NW-1\n    Fs: sampling frequency in Hz\n\n    Output:\n    mt_pxx: the spectrum (freq_num x channel_num)\n    freqs: frequencies (freq_num,)\n    \"\"\"\n    point_num, channel_num = eeg_seg.shape\n    # point_num, channel_num = eeg_seg.shape\n    nfft = max(1 << (point_num - 1).bit_length(), point_num)\n    freqs = np.arange(0, Fs, Fs * 1.0 / nfft)[:nfft // 2 + 1]  # list of frequencies\n\n    mt_pxx = np.zeros((len(freqs), channel_num))  # create the array to contain the spectrum\n\n    eeg_seg = detrend(eeg_seg, axis=0)  # remove the overall trend of the signal\n    for chi in range(channel_num):\n        _, pxx, _ = tsa.multi_taper_psd(eeg_seg[:, chi], Fs=Fs, NW=NW, adaptive=True, jackknife=False, low_bias=True,\n                                        NFFT=nfft)\n        mt_pxx[:, chi] = pxx\n\n    return mt_pxx, freqs\n\n\ndef mtspecgram_shq(eeg, movingwin, fpass, NW, Fs):\n    \"\"\"\n    Input:\n    eeg: numpy.array (signal_length x channel_num)\n    movingwin: [window length, window step] in seconds\n    fpass: [low, higher] in Hz\n    NW: Time-halfbandwidth product, 2 or 3 or 4 or ... #taper = 2NW-1\n    Fs: sampling frequency in Hz\n\n    Output:\n    spect: the spectrogram (window_num x freq_num x channel_num)\n    stimes: window starting times (window_num,)\n    sfreqs: frequencies (freq_num,)\n    \"\"\"\n    print(eeg.shape)\n    # signal_length, channel_num = eeg.shape\n    signal_length = eeg.shape[0]\n    window_length = int(round(movingwin[0] * Fs))\n    window_step = int(round(movingwin[1] * Fs))\n\n\n    window_start = np.arange(0, signal_length - window_length + 1, window_step)  # starting point of each segment\n    window_num = len(window_start)\n    print('%d windows'%window_num)\n    stimes = window_start * 1. / Fs\n\n    # Parallel\n    # n_jobs = 1  # number of cpus for parallel computing, -1 is all cpus\n    n_jobs = -1  # number of cpus for parallel computing, -1 is all cpus\n    verbose = 10  # verbosity in parallel computing\n    # res = Parallel(n_jobs=n_jobs, verbose=verbose)(\n    #    delayed(compute_spec_each_seg)(eeg[window_start[wi]:window_start[wi] + window_length, :], NW, Fs) for wi in range(window_num))\n\n    #res = Parallel(n_jobs=n_jobs, verbose=verbose)(\n    #   delayed(compute_spec_each_seg)(eeg[window_start[wi]:window_start[wi] + window_length].reshape(len(eeg[window_start[wi]:window_start[wi] + window_length]),1), NW, Fs) for wi in range(window_num))\n\n\n    # Iteration\n    res = []\n    for wi in range(window_num):\n        if wi%10==0:\n            print(wi)\n        #res.append(compute_spec_each_seg(eeg[window_start[wi]:window_start[wi] + window_length, :], NW, Fs))\n        na=np.array(eeg[window_start[wi]:window_start[wi] + window_length])\n        na=na.reshape(len(na), 1)\n        res.append(compute_spec_each_seg(na, NW, Fs))\n\n    sfreqs = res[0][1]\n    freq_good_ids = np.logical_and(sfreqs >= fpass[0], sfreqs < fpass[1])\n    sfreqs = sfreqs[freq_good_ids]\n\n    spect = np.array([rr[0][freq_good_ids] for rr in res])  # the spectrogram\n\n    return spect, stimes, sfreqs\n\n\n# Subfunc\nclass load_mat():\n    def __init__(self, filename, mode='r'):\n        self.filename = filename\n        self.mode = mode\n\n    def __enter__(self):\n        print('open')\n        # self.open_file = open(self.filename, self.mode)\n        return 0\n\n    def __exit__(self, *args):\n        # self.open_file.close()\n        print('close')\n        \ndef load(fp):\n    matfile = hdf5storage.loadmat(fp)\n    # print('Loading from %s' % fp)\n    return matfile\n\n\n\ndef step1_resample_spectrogram(fileName0):\n    #### 1.0 Loading data ####\n\n    # - input -\n    # dataPath = '/Data/'\n    # print('dataPath',dataPath)\n\n    # - output -\n    # targetFolder = catstr('/Output/')\n\n    #fileName0 = 'Case1_seg12.mat'\n\n    print('Loading', fileName0)\n    # fp=dataPath +fileName0\n    fp = fileName0\n    with load_mat(fp):\n        matfile = load(fp)\n        Fs = matfile['Fs']\n        start_time = matfile['start_time']\n        channels = matfile['channels']\n\n        eeg_data = matfile['data']\n\n    print('data', eeg_data.shape, Fs, start_time, channels)\n\n\n    # New: Resample to 200 Hz!!! %\n    # import scipy\n    # print(Fs)\n    # P=200\n    # Q=int(Fs)\n    # data=scipy.signal.resample(eeg_data.T, int(len(eeg_data.T) * P / Q))\n    # # data = np.resample(data, 200, Fs)\n    # eeg_data = data.T\n    Fs = 200\n\n    #### 1.1 Compute spectrograms ####\n    # just a toy example\n    #    eeg = np.random.rand(10000,6)\n    #print('resampled',eeg_data.shape)\n    spect, stimes, sfreqs = mtspecgram_shq(eeg_data[0,:].T, [2, 2], [0.5, 20], 2, Fs)\n    print('spect',spect.shape,spect)\n    print('stimes',stimes.shape,stimes)\n    \n    print('sfreqs',sfreqs.shape,sfreqs)\n    return [1]\n\n\nif __name__ == '__main__':\n    fp=\"Case5/Case5_seg4.mat\"\n    #loadData()\n    step1_resample_spectrogram(fp)"
        }, 
        {
            "execution_count": 29, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "('loading', 'Case5/Case5_seg4.mat')\n           index          0          1          2          3          4  \\\n0              0  43.065867  27.115546  43.331706  41.736674  29.773933   \n1              1  46.787609  31.900642  48.914318  46.787609  33.495674   \n2              2  45.458415  28.976417  50.775189  44.926738  31.634804   \n3              3  44.395061  28.178901  49.445996  40.407480  29.773933   \n4              4  44.926738  28.178901  47.053447  41.736674  30.305610   \n5              5  45.458415  30.039772  50.243512  44.926738  34.293191   \n6              6  46.787609  29.508094  54.496931  46.787609  32.963997   \n7              7  41.736674  25.786353  49.445996  39.078287  27.913062   \n8              8  36.685739  22.064611  43.331706  35.356545  25.254675   \n9              9  36.154061  23.127966  42.002512  36.685739  26.052191   \n10            10  38.546610  25.786353  45.724254  39.875803  27.115546   \n11            11  35.356545  21.267095  43.863383  32.963997  24.191320   \n12            12  29.773933  18.342869  36.951577  28.976417  21.532934   \n13            13  26.052191  18.342869  34.027352  28.444739  21.001256   \n14            14  24.191320  17.545353  33.229836  28.976417  19.140385   \n15            15  22.330450  14.621128  32.698158  22.862127  16.481999   \n16            16  18.342869  11.431064  25.786353  18.342869  12.760257   \n17            17  14.621128   9.570193  19.406224  16.481999  10.101870   \n18            18  15.152805  10.101870  21.267095  19.672063  13.291934   \n19            19  14.089450   9.570193  21.267095  19.672063  12.760257   \n20            20  10.101870   6.380128  15.684482  12.760257   7.709322   \n21            21  12.760257   8.240999  15.684482  17.811192   9.570193   \n22            22  12.228580   8.772677  15.684482  19.672063  12.760257   \n23            23  15.950321  11.962741  21.267095  25.254675  15.950321   \n24            24  15.950321   8.772677  19.406224  19.672063  12.760257   \n25            25  14.621128   7.709322  14.621128  18.342869  12.228580   \n26            26  15.950321  11.431064  16.481999  24.191320  14.621128   \n27            27  17.811192  13.823612  21.267095  28.976417  18.342869   \n28            28  20.203740  11.962741  23.393804  27.913062  18.342869   \n29            29  19.672063   9.570193  18.874547  24.722998  15.152805   \n...          ...        ...        ...        ...        ...        ...   \n9999969  9999969  24.722998   6.380128  18.874547  10.899386  -2.392548   \n9999970  9999970  24.191320   5.050935  20.203740   9.038515  -2.924226   \n9999971  9999971  30.305610  10.633547  23.393804  11.431064   0.797516   \n9999972  9999972  25.254675   5.848451  15.152805   7.709322  -4.785096   \n9999973  9999973  17.811192  -3.721742  10.101870   2.658387 -13.823612   \n9999974  9999974  26.583869   3.190064  21.267095  10.899386  -4.253419   \n9999975  9999975  30.305610  10.633547  25.254675  10.101870   0.797516   \n9999976  9999976  29.773933   7.709322  23.393804  11.431064  -1.063355   \n9999977  9999977  23.393804  -0.531677  17.545353   7.177645  -7.975161   \n9999978  9999978  31.103126   5.848451  27.115546  13.291934  -3.721742   \n9999979  9999979  36.685739  11.962741  34.027352  15.152805   4.519258   \n9999980  9999980  33.495674  14.621128  30.039772  11.431064   4.519258   \n9999981  9999981  34.293191  16.481999  31.368965  16.481999   5.050935   \n9999982  9999982  32.166481  10.101870  29.508094  14.089450  -0.531677   \n9999983  9999983  34.824868  14.621128  34.027352  13.291934   3.987580   \n9999984  9999984  31.103126  10.101870  27.647223   8.240999   1.329193   \n9999985  9999985  27.913062  10.101870  22.596288   8.240999  -1.063355   \n9999986  9999986  26.052191  11.962741  24.457159   9.570193   2.658387   \n9999987  9999987  29.773933   9.570193  29.508094  10.899386  -0.531677   \n9999988  9999988  30.305610  12.494418  28.976417   9.570193   1.329193   \n9999989  9999989  24.722998   7.709322  20.735418   4.519258  -4.785096   \n9999990  9999990  21.532934   7.709322  20.735418   5.050935  -5.582612   \n9999991  9999991  20.203740   8.772677  23.393804   3.190064  -2.924226   \n9999992  9999992  26.052191  13.823612  27.647223   6.380128   3.190064   \n9999993  9999993  21.001256   8.772677  21.267095   3.190064  -2.924226   \n9999994  9999994  19.140385   6.380128  18.874547   3.190064  -6.114290   \n9999995  9999995  23.393804  12.494418  27.647223  12.228580   2.126709   \n9999996  9999996  22.330450  13.823612  30.039772   7.177645   4.519258   \n9999997  9999997  20.203740   8.240999  24.457159   3.190064  -2.392548   \n9999998  9999998  27.115546  17.013676  31.368965  14.089450   6.380128   \n\n                 5          6          7          8  ...           24  \\\n0        32.166481  11.962741  28.976417  24.457159  ...  -517.853761   \n1        32.166481  17.545353  32.698158  30.039772  ...    52.636060   \n2        27.115546  13.823612  30.837288  23.393804  ...   563.046338   \n3        26.583869   9.570193  28.444739  17.545353  ...    80.814961   \n4        27.647223  11.431064  29.508094  21.267095  ...  -514.132020   \n5        25.254675  15.152805  33.495674  25.786353  ...  -157.642341   \n6        22.596288  14.355289  33.495674  23.925482  ...   513.068665   \n7        21.532934   6.911806  28.444739  14.621128  ...   280.193975   \n8        20.203740   4.519258  25.254675  12.760257  ...  -438.367994   \n9        19.672063   8.772677  27.115546  18.874547  ...  -346.919486   \n10       18.342869  11.962741  27.647223  20.203740  ...   383.871063   \n11       16.481999   6.911806  25.254675  12.760257  ...   442.355574   \n12       15.152805   5.848451  22.064611  11.431064  ...  -288.169136   \n13       15.152805   7.709322  22.064611  15.684482  ...  -476.382926   \n14       13.823612  10.101870  21.532934  17.013676  ...   200.708208   \n15       10.101870   5.050935  16.481999  11.962741  ...   535.930792   \n16        9.570193   3.190064  11.962741   6.380128  ...   -93.309379   \n17        9.570193   3.987580  10.899386   7.709322  ...  -535.664953   \n18        7.709322   8.772677  12.760257  15.152805  ...    -7.975161   \n19        6.911806   6.911806  10.899386  12.760257  ...   549.754404   \n20        8.240999   3.190064   6.380128   6.911806  ...   119.361570   \n21       12.760257   6.380128   8.240999  11.962741  ...  -511.739471   \n22       13.823612   9.570193  10.899386  18.342869  ...  -209.480885   \n23       15.152805  12.494418  13.291934  21.267095  ...   487.813990   \n24       13.823612   7.709322  10.101870  15.152805  ...   321.930649   \n25       14.621128   6.380128   9.038515  14.621128  ...  -407.530706   \n26       16.481999  10.101870  13.823612  20.735418  ...  -379.617644   \n27       18.874547  15.152805  16.481999  25.254675  ...   349.046195   \n28       18.342869  10.633547  15.152805  20.203740  ...   475.319571   \n29       17.811192   5.848451  13.823612  15.684482  ...  -241.647366   \n...            ...        ...        ...        ...  ...          ...   \n9999969  23.925482 -11.696902  -0.000000  -1.860871  ...  -108.993861   \n9999970  19.672063 -18.608708  -2.392548  -3.721742  ...   224.102013   \n9999971  22.064611 -12.228580   1.329193  -1.860871  ...   142.223697   \n9999972  18.874547 -15.418644  -4.253419  -8.506838  ...  -216.392691   \n9999973  15.684482 -26.583869  -9.836031 -12.494418  ...  -206.290821   \n9999974  22.596288 -19.937901  -1.063355  -4.785096  ...   150.198858   \n9999975  22.064611 -13.026096  -0.000000  -6.645967  ...   202.569079   \n9999976  23.925482 -15.418644   1.329193  -4.253419  ...  -144.350407   \n9999977  20.735418 -31.634804  -3.721742  -6.114290  ...  -256.800171   \n9999978  23.393804 -26.052191   0.797516  -4.253419  ...    64.598801   \n9999979  21.532934 -13.026096   5.848451  -3.721742  ...   246.964140   \n9999980  16.481999 -11.165225   2.658387  -7.443483  ...   -47.850964   \n9999981  19.672063  -8.506838   6.380128  -2.392548  ...  -275.674718   \n9999982  18.874547 -22.862127   3.987580  -2.392548  ...   -44.660899   \n9999983  17.013676 -16.216160   4.519258  -4.253419  ...   249.356688   \n9999984  10.101870 -21.001256   1.329193  -8.506838  ...    71.510607   \n9999985  10.101870 -19.140385  -0.531677 -10.367709  ...  -258.661042   \n9999986  11.431064 -11.165225   0.797516  -7.443483  ...  -131.855988   \n9999987  10.101870 -24.722998   2.658387  -4.785096  ...   219.051078   \n9999988  10.899386 -20.469579   1.329193  -9.304354  ...   157.908180   \n9999989   7.709322 -23.659643  -4.785096 -14.355289  ...  -211.341756   \n9999990   7.709322 -22.330450  -4.253419 -11.165225  ...  -218.253562   \n9999991   3.987580 -14.355289  -3.721742 -10.367709  ...   141.426181   \n9999992   4.519258  -7.443483  -0.000000  -9.304354  ...   235.001399   \n9999993   2.126709 -18.608708  -4.785096 -11.165225  ...  -117.234861   \n9999994   6.380128 -22.330450  -4.253419  -9.836031  ...  -272.484654   \n9999995  10.101870 -11.165225   3.987580  -4.253419  ...    43.597545   \n9999996  -0.531677 -11.696902   3.190064  -6.114290  ...   264.509493   \n9999997  -0.531677 -25.520514  -1.860871 -11.165225  ...   -17.545353   \n9999998  11.431064 -13.026096   8.240999  -1.860871  ...  -270.623783   \n\n                25         26          27         28         29           30  \\\n0        15.684482   0.797516 -588.301013  -2.924226 -15.684482   631.366880   \n1        17.545353   4.519258   38.812448  75.764026  74.168994  -723.347066   \n2        14.355289   0.797516  631.632719  45.724254  57.686995  -774.653932   \n3        11.431064  -0.531677  108.462184 -39.078287 -35.888223   665.394232   \n4        11.431064   0.797516 -576.604111 -24.191320 -34.559029   909.699985   \n5        13.291934   1.329193 -197.783983  60.079543  55.826124  -395.567965   \n6        12.494418   0.797516  567.565596  64.332962  75.498187  -967.121141   \n7         8.240999  -3.455903  332.298358 -25.520514 -15.684482   287.371620   \n8         3.987580  -4.785096 -481.965538 -45.458415 -52.370221  1052.721198   \n9         5.050935  -4.253419 -403.277287  34.559029  26.583869   -28.178901   \n10        7.709322  -1.595032  417.632576  73.903155  79.751606 -1010.984524   \n11        6.911806  -1.063355  509.878601  -1.860871   8.240999  -139.565310   \n12        4.519258  -1.595032 -307.841199 -53.699415 -58.218672  1056.442940   \n13        5.050935  -4.253419 -544.703468  10.633547  -0.000000   354.894646   \n14        6.380128  -2.924226  207.354175  72.573961  74.168994  -905.712405   \n15        6.380128  -1.595032  606.909721  20.735418  32.432320  -547.096017   \n16        3.987580  -1.595032  -84.802541 -54.231092 -55.560285   875.938472   \n17        3.190064  -4.253419 -604.783012 -17.279515 -29.508094   689.053875   \n18        7.709322  -4.253419  -28.178901  65.130478  60.877059  -667.520942   \n19        7.709322  -1.063355  616.745753  45.724254  55.294447  -838.721056   \n20        4.519258  -1.063355  152.591406 -42.268351 -39.078287   569.958144   \n21        5.050935  -0.000000 -569.958144 -32.963997 -44.129222   942.929821   \n22        6.911806  -0.531677 -252.546752  53.167737  45.192577  -337.083454   \n23       11.962741   3.190064  538.057501  70.181413  76.029864 -1010.984524   \n24        8.772677   3.190064  375.895903 -16.216160  -9.304354   173.060985   \n25        8.240999   1.860871 -447.406509 -44.926738 -55.028608  1054.582069   \n26        9.570193  -0.531677 -440.760542  33.761513  22.862127    52.901899   \n27       11.431064   3.190064  376.959257  81.346638  83.739186 -1014.174589   \n28       11.962741   3.721742  542.576759  10.633547  18.608708  -246.166624   \n29        7.709322   0.797516 -257.597687 -49.180157 -55.028608  1015.769621   \n...            ...        ...         ...        ...        ...          ...   \n9999969  31.103126 -23.925482 -136.375246  18.874547  12.760257    25.786353   \n9999970  31.900642 -23.925482  264.509493  20.735418  17.811192  -212.936788   \n9999971  40.407480 -22.064611  179.175275 -23.659643 -25.786353   -32.432320   \n9999972  31.900642 -30.837288 -247.761656 -38.546610 -45.458415   189.542983   \n9999973  18.874547 -33.229836 -245.900785  -0.531677  -7.975161    58.484511   \n9999974  30.039772 -29.508094  176.516888  24.457159  21.001256  -214.265981   \n9999975  34.293191 -33.229836  252.812591 -14.355289 -16.216160  -171.731791   \n9999976  30.571449 -27.647223 -155.515632 -41.736674 -46.787609   134.248537   \n9999977  23.127966 -30.039772 -303.587780  -9.304354 -17.013676   177.580243   \n9999978  19.937901 -29.508094   70.713091  28.178901  20.469579  -105.803797   \n9999979  30.571449 -27.647223  300.929393   1.329193  -1.063355  -214.265981   \n9999980  26.318030 -32.698158  -37.483255 -41.204996 -44.926738    67.788865   \n9999981  24.457159 -27.115546 -320.867295 -15.418644 -22.596288   190.606338   \n9999982  23.659643 -25.254675  -56.357802  24.988837  18.608708   -70.181413   \n9999983  24.988837 -30.039772  300.131877  13.291934  11.431064  -210.012562   \n9999984  21.267095 -30.039772   99.689507 -36.154061 -38.546610    37.217416   \n9999985  13.291934 -32.698158 -298.005167 -34.824868 -40.407480   221.443626   \n9999986  13.291934 -31.900642 -161.629921  14.621128   7.709322    56.623640   \n9999987  14.355289 -24.457159  262.116945  21.267095  19.140385  -202.303240   \n9999988  17.013676 -25.786353  204.164111 -26.052191 -26.318030   -95.170250   \n9999989   7.709322 -30.039772 -235.267237 -46.787609 -49.180157   187.682113   \n9999990   1.329193 -30.837288 -260.521913  -1.860871  -6.911806   148.072148   \n9999991  -2.392548 -35.090707  164.819986  20.735418  19.672063  -132.121827   \n9999992  10.101870 -30.837288  289.764168 -14.355289 -11.962741   -90.119315   \n9999993   4.519258 -30.039772 -122.817473 -47.319286 -48.648480   190.606338   \n9999994  -4.253419 -29.508094 -317.677230 -16.747837 -21.267095   193.264725   \n9999995   2.126709 -28.976417   50.509350  26.318030  24.722998   -73.105639   \n9999996   5.050935 -24.457159  321.133133   3.190064   5.316774  -157.908180   \n9999997   1.329193 -30.837288   -2.392548 -43.597545 -44.129222   107.398829   \n9999998   6.911806 -22.596288 -317.677230 -18.608708 -22.596288   279.130621   \n\n                 31        time  case  \n0       -207.354175    76799232     5  \n1       -418.430092    76799488     5  \n2        136.906924    76799744     5  \n3        498.979214    76800000     5  \n4        -26.052191    76800256     5  \n5       -448.204025    76800512     5  \n6        -44.660899    76800768     5  \n7        488.345667    76801024     5  \n8        153.654761    76801280     5  \n9       -425.341898    76801536     5  \n10      -217.987723    76801792     5  \n11       406.999029    76802048     5  \n12       330.437487    76802304     5  \n13      -322.196488    76802560     5  \n14      -353.299614    76802816     5  \n15       263.446138    76803072     5  \n16       447.938187    76803328     5  \n17      -173.060985    76803584     5  \n18      -437.038800    76803840     5  \n19        92.777702    76804096     5  \n20       494.459957    76804352     5  \n21        10.101870    76804608     5  \n22      -453.254960    76804864     5  \n23       -86.929250    76805120     5  \n24       475.851249    76805376     5  \n25       200.708208    76805632     5  \n26      -399.289707    76805888     5  \n27      -248.293333    76806144     5  \n28       382.807708    76806400     5  \n29       361.540614    76806656     5  \n...             ...         ...   ...  \n9999969 -256.268494  2636791296     5  \n9999970 -586.705981  2636791552     5  \n9999971  254.141784  2636791808     5  \n9999972  616.214075  2636792064     5  \n9999973 -115.373990  2636792320     5  \n9999974 -707.396745  2636792576     5  \n9999975 -161.364083  2636792832     5  \n9999976  562.248822  2636793088     5  \n9999977  205.227466  2636793344     5  \n9999978 -558.261241  2636793600     5  \n9999979 -384.934418  2636793856     5  \n9999980  471.597830  2636794112     5  \n9999981  346.121970  2636794368     5  \n9999982 -515.461213  2636794624     5  \n9999983 -523.436374  2636794880     5  \n9999984  398.758030  2636795136     5  \n9999985  539.918372  2636795392     5  \n9999986 -226.494561  2636795648     5  \n9999987 -645.190492  2636795904     5  \n9999988   38.546610  2636796160     5  \n9999989  571.021498  2636796416     5  \n9999990   26.318030  2636796672     5  \n9999991 -608.504753  2636796928     5  \n9999992  -64.332962  2636797184     5  \n9999993  650.507266  2636797440     5  \n9999994  201.239886  2636797696     5  \n9999995 -572.616531  2636797952     5  \n9999996 -374.300870  2636798208     5  \n9999997  490.738215  2636798464     5  \n9999998  490.206538  2636798720     5  \n\n[9999999 rows x 35 columns]\n"
                }
            ], 
            "source": "def loadFile(fileName0):\n    print('loading',fileName0)\n    r=fileName0\n    mat = hdf5storage.loadmat(fileName0) \n    #spect, stimes, sfreqs = mtspecgram_shq(mat['data'], [2,2], [0.5, 20], 2, 200)\n    #print mat['data']\n    sampleRate = np.round(mat['Fs'])\n    #print sampleRate\n    #os.remove(os.path.basename(fileName0))\n    #transpose\n    rawDat = pd.DataFrame(mat['data'])\n    rawDat = rawDat.T\n    #label columns\n    #add time column\n    #calculate time column\n    fileNum = r[:len(r)-4]\n    fileNum = re.search('(\\d+)$', fileNum).group(0)\n    #print fileNum\n    rawDat.reset_index(inplace=True)\n    #print rawDat\n    #rawDat['index']=rawDat.index\n    rawDat['time'] = rawDat['index'].apply(lambda e: timeStamp(e,fileNum,sampleRate))\n    caseNum = int(re.search(r'\\d+', fileName0).group())\n    rawDat['case'] = caseNum\n\n    return rawDat\n\ndef timeStamp(ind,fileNum,sampleRate):\n    start = (int(fileNum) - 1) * 99999\n    row = start + int(ind)\n    time = row*int(sampleRate)\n    return time\n\nimport pandas as pd\nimport re\nif __name__ == '__main__':\n    fp=\"Case5/Case5_seg4.mat\"\n    #loadData()\n    print(loadFile(fp))"
        }, 
        {
            "execution_count": 44, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 44, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "ParallelCollectionRDD[61] at parallelize at PythonRDD.scala:475"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# Load\n\ndata = [\"Case5/Case5_seg4.mat\",\"Case5/Case5_seg3.mat\"]\ndistData = sc.parallelize(data)\ndistData.repartition(len(data))\ndistData.cache()"
        }, 
        {
            "execution_count": 45, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "ename": "Py4JJavaError", 
                    "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 11.0 failed 10 times, most recent failure: Lost task 0.9 in stage 11.0 (TID 119, yp-spark-dal09-env5-0021, executor 18213d4d-31bb-4ac8-b442-3904b593af90): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/src/spark21master/spark-2.1.0-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 174, in main\n    process()\n  File \"/usr/local/src/spark21master/spark-2.1.0-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 169, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/src/spark21master/spark-2.1.0-bin-2.7.3/python/lib/pyspark.zip/pyspark/serializers.py\", line 268, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/src/spark21master/spark/python/pyspark/rdd.py\", line 1339, in takeUpToNumLeft\n    yield next(iterator)\n  File \"<ipython-input-36-9cb729501f9e>\", line 130, in step1_resample_spectrogram\n  File \"<ipython-input-36-9cb729501f9e>\", line 108, in load\n  File \"/gpfs/fs01/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages/hdf5storage/__init__.py\", line 1768, in loadmat\n    with h5py.File(filename, mode='r') as f:\n  File \"/gpfs/fs01/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages/h5py/_hl/files.py\", line 271, in __init__\n    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)\n  File \"/gpfs/fs01/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages/h5py/_hl/files.py\", line 101, in make_fid\n    fid = h5f.open(name, flags, fapl=fapl)\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper (/tmp/pip-rdtLFq-build/h5py/_objects.c:2840)\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper (/tmp/pip-rdtLFq-build/h5py/_objects.c:2798)\n  File \"h5py/h5f.pyx\", line 78, in h5py.h5f.open (/tmp/pip-rdtLFq-build/h5py/h5f.c:2117)\nIOError: Unable to open file (Unable to open file: name = 'case5/case5_seg4.mat', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:326)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:290)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1153)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.lang.Thread.run(Thread.java:785)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1442)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1430)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1429)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1429)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:803)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1657)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1612)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1601)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat java.lang.Thread.getStackTrace(Thread.java:1117)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:629)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1931)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1944)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1957)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:441)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:507)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:785)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/src/spark21master/spark-2.1.0-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 174, in main\n    process()\n  File \"/usr/local/src/spark21master/spark-2.1.0-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 169, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/src/spark21master/spark-2.1.0-bin-2.7.3/python/lib/pyspark.zip/pyspark/serializers.py\", line 268, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/src/spark21master/spark/python/pyspark/rdd.py\", line 1339, in takeUpToNumLeft\n    yield next(iterator)\n  File \"<ipython-input-36-9cb729501f9e>\", line 130, in step1_resample_spectrogram\n  File \"<ipython-input-36-9cb729501f9e>\", line 108, in load\n  File \"/gpfs/fs01/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages/hdf5storage/__init__.py\", line 1768, in loadmat\n    with h5py.File(filename, mode='r') as f:\n  File \"/gpfs/fs01/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages/h5py/_hl/files.py\", line 271, in __init__\n    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)\n  File \"/gpfs/fs01/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages/h5py/_hl/files.py\", line 101, in make_fid\n    fid = h5f.open(name, flags, fapl=fapl)\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper (/tmp/pip-rdtLFq-build/h5py/_objects.c:2840)\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper (/tmp/pip-rdtLFq-build/h5py/_objects.c:2798)\n  File \"h5py/h5f.pyx\", line 78, in h5py.h5f.open (/tmp/pip-rdtLFq-build/h5py/h5f.c:2117)\nIOError: Unable to open file (Unable to open file: name = 'case5/case5_seg4.mat', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:326)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:290)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1153)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n", 
                    "traceback": [
                        "\u001b[0;31m\u001b[0m", 
                        "\u001b[0;31mPy4JJavaError\u001b[0mTraceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-45-940a17a3aab9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mjustData3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep1_resample_spectrogram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mjustData3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", 
                        "\u001b[0;32m/usr/local/src/spark21master/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumPartsToTry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotalParts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1343\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeUpToNumLeft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m             \u001b[0mitems\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/spark21master/spark/python/pyspark/context.py\u001b[0m in \u001b[0;36mrunJob\u001b[0;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[1;32m    963\u001b[0m         \u001b[0;31m# SparkContext#runJob.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0mmappedRDD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitionFunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m         \u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/spark21master/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/spark21master/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/spark21master/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    317\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 raise Py4JError(\n", 
                        "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 11.0 failed 10 times, most recent failure: Lost task 0.9 in stage 11.0 (TID 119, yp-spark-dal09-env5-0021, executor 18213d4d-31bb-4ac8-b442-3904b593af90): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/src/spark21master/spark-2.1.0-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 174, in main\n    process()\n  File \"/usr/local/src/spark21master/spark-2.1.0-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 169, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/src/spark21master/spark-2.1.0-bin-2.7.3/python/lib/pyspark.zip/pyspark/serializers.py\", line 268, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/src/spark21master/spark/python/pyspark/rdd.py\", line 1339, in takeUpToNumLeft\n    yield next(iterator)\n  File \"<ipython-input-36-9cb729501f9e>\", line 130, in step1_resample_spectrogram\n  File \"<ipython-input-36-9cb729501f9e>\", line 108, in load\n  File \"/gpfs/fs01/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages/hdf5storage/__init__.py\", line 1768, in loadmat\n    with h5py.File(filename, mode='r') as f:\n  File \"/gpfs/fs01/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages/h5py/_hl/files.py\", line 271, in __init__\n    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)\n  File \"/gpfs/fs01/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages/h5py/_hl/files.py\", line 101, in make_fid\n    fid = h5f.open(name, flags, fapl=fapl)\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper (/tmp/pip-rdtLFq-build/h5py/_objects.c:2840)\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper (/tmp/pip-rdtLFq-build/h5py/_objects.c:2798)\n  File \"h5py/h5f.pyx\", line 78, in h5py.h5f.open (/tmp/pip-rdtLFq-build/h5py/h5f.c:2117)\nIOError: Unable to open file (Unable to open file: name = 'case5/case5_seg4.mat', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:326)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:290)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1153)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.lang.Thread.run(Thread.java:785)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1442)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1430)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1429)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1429)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:803)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1657)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1612)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1601)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat java.lang.Thread.getStackTrace(Thread.java:1117)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:629)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1931)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1944)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1957)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:441)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:507)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:785)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/src/spark21master/spark-2.1.0-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 174, in main\n    process()\n  File \"/usr/local/src/spark21master/spark-2.1.0-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 169, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/src/spark21master/spark-2.1.0-bin-2.7.3/python/lib/pyspark.zip/pyspark/serializers.py\", line 268, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/src/spark21master/spark/python/pyspark/rdd.py\", line 1339, in takeUpToNumLeft\n    yield next(iterator)\n  File \"<ipython-input-36-9cb729501f9e>\", line 130, in step1_resample_spectrogram\n  File \"<ipython-input-36-9cb729501f9e>\", line 108, in load\n  File \"/gpfs/fs01/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages/hdf5storage/__init__.py\", line 1768, in loadmat\n    with h5py.File(filename, mode='r') as f:\n  File \"/gpfs/fs01/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages/h5py/_hl/files.py\", line 271, in __init__\n    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)\n  File \"/gpfs/fs01/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages/h5py/_hl/files.py\", line 101, in make_fid\n    fid = h5f.open(name, flags, fapl=fapl)\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper (/tmp/pip-rdtLFq-build/h5py/_objects.c:2840)\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper (/tmp/pip-rdtLFq-build/h5py/_objects.c:2798)\n  File \"h5py/h5f.pyx\", line 78, in h5py.h5f.open (/tmp/pip-rdtLFq-build/h5py/h5f.c:2117)\nIOError: Unable to open file (Unable to open file: name = 'case5/case5_seg4.mat', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:326)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:290)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1153)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n"
                    ], 
                    "output_type": "error"
                }
            ], 
            "source": "justData3 = distData.flatMap(step1_resample_spectrogram)\njustData3.take(2)"
        }, 
        {
            "execution_count": 34, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "PythonRDD[53] at RDD at PythonRDD.scala:48\n"
                }, 
                {
                    "ename": "Py4JJavaError", 
                    "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 10.0 failed 10 times, most recent failure: Lost task 0.9 in stage 10.0 (TID 109, yp-spark-dal09-env5-0027, executor bf8add15-869e-4583-b14b-28161ca67e25): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/src/spark21master/spark-2.1.0-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 174, in main\n    process()\n  File \"/usr/local/src/spark21master/spark-2.1.0-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 169, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/src/spark21master/spark-2.1.0-bin-2.7.3/python/lib/pyspark.zip/pyspark/serializers.py\", line 268, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"<ipython-input-29-f8665c8abae2>\", line 4, in loadFile\n  File \"/gpfs/fs01/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages/hdf5storage/__init__.py\", line 1768, in loadmat\n    with h5py.File(filename, mode='r') as f:\n  File \"/gpfs/fs01/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages/h5py/_hl/files.py\", line 271, in __init__\n    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)\n  File \"/gpfs/fs01/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages/h5py/_hl/files.py\", line 101, in make_fid\n    fid = h5f.open(name, flags, fapl=fapl)\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper (/tmp/pip-rdtLFq-build/h5py/_objects.c:2840)\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper (/tmp/pip-rdtLFq-build/h5py/_objects.c:2798)\n  File \"h5py/h5f.pyx\", line 78, in h5py.h5f.open (/tmp/pip-rdtLFq-build/h5py/h5f.c:2117)\nIOError: Unable to open file (Unable to open file: name = 'case5/case5_seg4.mat', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:326)\n\tat org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:339)\n\tat org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:337)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:980)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:955)\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:895)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:955)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:701)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:337)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:326)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:290)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1153)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.lang.Thread.run(Thread.java:785)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1442)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1430)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1429)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1429)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:803)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1657)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1612)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1601)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat java.lang.Thread.getStackTrace(Thread.java:1117)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:629)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1931)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1944)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1957)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:441)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:507)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:785)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/src/spark21master/spark-2.1.0-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 174, in main\n    process()\n  File \"/usr/local/src/spark21master/spark-2.1.0-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 169, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/src/spark21master/spark-2.1.0-bin-2.7.3/python/lib/pyspark.zip/pyspark/serializers.py\", line 268, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"<ipython-input-29-f8665c8abae2>\", line 4, in loadFile\n  File \"/gpfs/fs01/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages/hdf5storage/__init__.py\", line 1768, in loadmat\n    with h5py.File(filename, mode='r') as f:\n  File \"/gpfs/fs01/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages/h5py/_hl/files.py\", line 271, in __init__\n    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)\n  File \"/gpfs/fs01/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages/h5py/_hl/files.py\", line 101, in make_fid\n    fid = h5f.open(name, flags, fapl=fapl)\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper (/tmp/pip-rdtLFq-build/h5py/_objects.c:2840)\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper (/tmp/pip-rdtLFq-build/h5py/_objects.c:2798)\n  File \"h5py/h5f.pyx\", line 78, in h5py.h5f.open (/tmp/pip-rdtLFq-build/h5py/h5f.c:2117)\nIOError: Unable to open file (Unable to open file: name = 'case5/case5_seg4.mat', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:326)\n\tat org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:339)\n\tat org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:337)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:980)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:955)\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:895)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:955)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:701)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:337)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:326)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:290)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1153)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n", 
                    "traceback": [
                        "\u001b[0;31m\u001b[0m", 
                        "\u001b[0;31mPy4JJavaError\u001b[0mTraceback (most recent call last)", 
                        "\u001b[0;32m<ipython-input-34-685ec83965d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mjustData3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjustData3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mjustData3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", 
                        "\u001b[0;32m/usr/local/src/spark21master/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumPartsToTry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotalParts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1343\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeUpToNumLeft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m             \u001b[0mitems\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/spark21master/spark/python/pyspark/context.py\u001b[0m in \u001b[0;36mrunJob\u001b[0;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[1;32m    963\u001b[0m         \u001b[0;31m# SparkContext#runJob.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0mmappedRDD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitionFunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m         \u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/spark21master/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/spark21master/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", 
                        "\u001b[0;32m/usr/local/src/spark21master/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    317\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 raise Py4JError(\n", 
                        "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 10.0 failed 10 times, most recent failure: Lost task 0.9 in stage 10.0 (TID 109, yp-spark-dal09-env5-0027, executor bf8add15-869e-4583-b14b-28161ca67e25): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/src/spark21master/spark-2.1.0-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 174, in main\n    process()\n  File \"/usr/local/src/spark21master/spark-2.1.0-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 169, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/src/spark21master/spark-2.1.0-bin-2.7.3/python/lib/pyspark.zip/pyspark/serializers.py\", line 268, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"<ipython-input-29-f8665c8abae2>\", line 4, in loadFile\n  File \"/gpfs/fs01/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages/hdf5storage/__init__.py\", line 1768, in loadmat\n    with h5py.File(filename, mode='r') as f:\n  File \"/gpfs/fs01/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages/h5py/_hl/files.py\", line 271, in __init__\n    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)\n  File \"/gpfs/fs01/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages/h5py/_hl/files.py\", line 101, in make_fid\n    fid = h5f.open(name, flags, fapl=fapl)\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper (/tmp/pip-rdtLFq-build/h5py/_objects.c:2840)\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper (/tmp/pip-rdtLFq-build/h5py/_objects.c:2798)\n  File \"h5py/h5f.pyx\", line 78, in h5py.h5f.open (/tmp/pip-rdtLFq-build/h5py/h5f.c:2117)\nIOError: Unable to open file (Unable to open file: name = 'case5/case5_seg4.mat', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:326)\n\tat org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:339)\n\tat org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:337)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:980)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:955)\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:895)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:955)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:701)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:337)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:326)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:290)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1153)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.lang.Thread.run(Thread.java:785)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1442)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1430)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1429)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1429)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:803)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1657)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1612)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1601)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat java.lang.Thread.getStackTrace(Thread.java:1117)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:629)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1931)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1944)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1957)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:441)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:95)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)\n\tat java.lang.reflect.Method.invoke(Method.java:507)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:785)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/src/spark21master/spark-2.1.0-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 174, in main\n    process()\n  File \"/usr/local/src/spark21master/spark-2.1.0-bin-2.7.3/python/lib/pyspark.zip/pyspark/worker.py\", line 169, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/src/spark21master/spark-2.1.0-bin-2.7.3/python/lib/pyspark.zip/pyspark/serializers.py\", line 268, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"<ipython-input-29-f8665c8abae2>\", line 4, in loadFile\n  File \"/gpfs/fs01/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages/hdf5storage/__init__.py\", line 1768, in loadmat\n    with h5py.File(filename, mode='r') as f:\n  File \"/gpfs/fs01/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages/h5py/_hl/files.py\", line 271, in __init__\n    fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr)\n  File \"/gpfs/fs01/user/seff-34c2f0d3dcc620-a916a00b641d/.local/lib/python2.7/site-packages/h5py/_hl/files.py\", line 101, in make_fid\n    fid = h5f.open(name, flags, fapl=fapl)\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper (/tmp/pip-rdtLFq-build/h5py/_objects.c:2840)\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper (/tmp/pip-rdtLFq-build/h5py/_objects.c:2798)\n  File \"h5py/h5f.pyx\", line 78, in h5py.h5f.open (/tmp/pip-rdtLFq-build/h5py/h5f.c:2117)\nIOError: Unable to open file (Unable to open file: name = 'case5/case5_seg4.mat', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:326)\n\tat org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:339)\n\tat org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:337)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:980)\n\tat org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:955)\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:895)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:955)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:701)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:337)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:326)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:290)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1153)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n"
                    ], 
                    "output_type": "error"
                }
            ], 
            "source": "justData3 = distData.flatMap(loadFile)\njustData3.cache()\nprint(justData3)\njustData3.take(2)"
        }, 
        {
            "execution_count": 15, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Case3/Case3_seg4.mat\r\n"
                }
            ], 
            "source": "!ls Case3/Case3_seg4.mat"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2 with Spark 2.1", 
            "name": "python2-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "2.7.11", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython2", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}
{
    "nbformat_minor": 0, 
    "cells": [
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": false
            }, 
            "outputs": [], 
            "source": "#!pip uninstall dist-keras -y"
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "#!pip install --upgrade keras"
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "#!pip install dist-keras"
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": false
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "Using TensorFlow backend.\n"
                }
            ], 
            "source": "import numpy as np\n\nimport time\n\nimport requests\n\nfrom keras.optimizers import *\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation\n\nfrom pyspark import SparkContext\nfrom pyspark import SparkConf\n\nfrom pyspark.ml.feature import StandardScaler\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.mllib.evaluation import BinaryClassificationMetrics\n\nfrom distkeras.trainers import *\nfrom distkeras.predictors import *\nfrom distkeras.transformers import *\nfrom distkeras.evaluators import *\nfrom distkeras.utils import *"
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": false
            }, 
            "outputs": [], 
            "source": "def setHadoopConfig(name):\n    prefix = \"fs.swift2d.service.\" + name\n    hconf = sc._jsc.hadoopConfiguration()\n    hconf.set(prefix + '.auth.url', 'https://identity.open.softlayer.com'+'/v3/auth/tokens')\n    hconf.set(prefix + '.auth.endpoint.prefix', 'endpoints')\n    hconf.set(prefix + '.tenant', 'a9fb4d478e3d40a8bbd54c5a2ecf25a3')\n    hconf.set(prefix + '.username', '6a4cc8251c1940179a6cccc9098a15e0')\n    hconf.set(prefix + '.password', 'kDTcKA2H(3eo5.G0')\n    hconf.setInt(prefix + '.http.port', 8080)\n    hconf.set(prefix + '.region', 'dallas')\n    hconf.setBoolean(prefix + '.public', False)\n\nname = \"keystone\"\nsetHadoopConfig(name)\n\nseven_cases = spark.read.parquet(\"swift2d://MGH.\" + name + \"/tempParq/7cases.parquet\")"
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": false
            }, 
            "outputs": [], 
            "source": "numClasses = seven_cases.select(\"prediction\").distinct().count()\nnumFeats = len(seven_cases.select(\"pcaFeatures\").limit(1).toPandas()['pcaFeatures'][0])\n\nseven_cases = seven_cases.withColumnRenamed(\"prediction\",\"label_index\").select(\"label_index\",\"pcaFeatures\")\nencoder = OneHotTransformer(output_dim=numClasses,input_col=\"label_index\", output_col=\"label\")\nencoded = encoder.transform(seven_cases)"
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": false
            }, 
            "outputs": [
                {
                    "execution_count": 7, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[Row(label_index=0, pcaFeatures=DenseVector([-0.9483, 0.0061, 0.0236, 0.0304, 0.3027, -0.0294, 0.0723, -0.0325, -0.0037, 0.0106, -0.0104, -0.0076, 0.0037, 0.0031, 0.0039, -0.0076, -0.0015, 0.0007, -0.0005, 0.0009, 0.0, 0.0018, -0.0008, 0.0003, -0.0013, -0.0028, 0.001, 0.0004, -0.0006, 0.0002, 0.0003, 0.0009, -0.0001, 0.0, 0.0003, -0.0003, -0.0001, -0.0004, 0.0002, 0.0, -0.0, 0.0, -0.0, 0.0002, 0.0003, -0.0, -0.0002, -0.0005, -0.0, -0.0, -0.0, -0.0, 0.0, -0.0001, -0.0002, 0.0002, 0.0001, -0.0, 0.0001, -0.0002, -0.0001, 0.0, 0.0, 0.0, -0.0, -0.0, -0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, 0.0, -0.0, 0.0, -0.0, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0, -0.0, 0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, 0.0, 0.0]), label=[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n Row(label_index=0, pcaFeatures=DenseVector([-0.9482, 0.0122, 0.02, 0.0251, 0.3029, -0.0327, 0.0754, -0.0225, -0.0051, 0.0152, -0.017, -0.0043, -0.0012, 0.0059, 0.0066, -0.0078, -0.0055, -0.0008, -0.0009, 0.0009, 0.0035, 0.0033, 0.0028, 0.0008, -0.0015, -0.0012, 0.0037, 0.0008, -0.0007, 0.0001, -0.0011, 0.001, -0.0001, -0.0003, 0.0003, -0.0004, -0.0001, -0.0005, 0.0002, -0.0001, 0.0, 0.0, -0.0, 0.0001, 0.0004, 0.0001, -0.0002, -0.0005, -0.0, 0.0, -0.0, -0.0, 0.0, 0.0, -0.0001, 0.0001, 0.0001, 0.0, 0.0, -0.0001, -0.0, -0.0, -0.0001, 0.0001, 0.0, 0.0, -0.0, 0.0, 0.0, 0.0, -0.0, -0.0, 0.0001, 0.0, -0.0, -0.0, 0.0, -0.0, 0.0, 0.0, -0.0, -0.0, 0.0, 0.0, -0.0, 0.0001, -0.0, -0.0, -0.0, 0.0, -0.0, 0.0, -0.0, 0.0, -0.0, -0.0, 0.0, 0.0, 0.0, -0.0]), label=[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "(training_set, test_set) = encoded.randomSplit([0.8, 0.2])\ntraining_set.cache()\ntest_set.cache()\n\ntraining_set.repartition(50)\ntraining_set.take(2)"
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": false
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_1 (Dense)              (None, 512)               51712     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 256)               131328    \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 256)               0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 128)               32896     \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 64)                8256      \n_________________________________________________________________\ndense_5 (Dense)              (None, 32)                2080      \n_________________________________________________________________\ndense_6 (Dense)              (None, 18)                594       \n=================================================================\nTotal params: 226,866\nTrainable params: 226,866\nNon-trainable params: 0\n_________________________________________________________________\n"
                }
            ], 
            "source": "model = Sequential()\nmodel.add(Dense(512, input_shape=(numFeats,),activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(256,activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(128,activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(64,activation='relu'))\nmodel.add(Dense(32,activation='relu'))\nmodel.add(Dense(numClasses,activation='softmax'))\n\nmodel.summary()"
        }, 
        {
            "execution_count": 9, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": "results = {}\n\ndef evaluate_accuracy(model, test_set, ohLabel, iLabel, pred, feats):\n    \n    evaluator = AccuracyEvaluator(prediction_col=pred, label_col=iLabel)\n    test_set = test_set.select(feats, iLabel, ohLabel)\n    predictor = ModelPredictor(keras_model=model, features_col=feats)\n    test_set = predictor.predict(test_set)\n    index_transformer = LabelIndexTransformer(output_dim=numClasses)\n    test_set = index_transformer.transform(test_set)\n    score = evaluator.evaluate(test_set)\n    \n    return score\n\ndef add_result(trainer, accuracy, dt):\n    global results;\n    \n    # Store the metrics.\n    results[trainer] = {}\n    results[trainer]['accuracy'] = accuracy;\n    results[trainer]['time_spent'] = dt\n    # Display the metrics.\n    print(\"Trainer: \" + str(trainer))\n    print(\" - Accuracy: \" + str(accuracy))\n    print(\" - Training time: \" + str(dt))"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": false
            }, 
            "outputs": [], 
            "source": "optimizer = 'adagrad'\n#optimizer = 'adam'\nloss = 'categorical_crossentropy'\n\ntrainer = ADAG(keras_model=model, worker_optimizer=optimizer, loss=loss, metrics=[\"accuracy\"], num_workers=60, batch_size=16,\n     features_col=\"pcaFeatures\", label_col=\"label\", num_epoch=100, communication_window=15)\n#trainer = DOWNPOUR(keras_model=model, worker_optimizer=optimizer, loss=loss, num_workers=50,\n#                   batch_size=32, communication_window=4, num_epoch=100,\n#                   features_col=\"pcaFeatures\", label_col=\"label\")\ntrainer.set_parallelism_factor(2)\n#test_set training_set\ntrained_model = trainer.train(training_set)"
        }, 
        {
            "execution_count": 13, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": false
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Trainer: adag\n - Accuracy: 0.9789330958837577\n - Training time: 391.0852265357971\n"
                }
            ], 
            "source": "#evaluator = AccuracyEvaluator(prediction_col=\"prediction_index\", label_col=\"label_index\")\n#test_set = test_set.select(\"pcaFeatures\", \"label_index\", \"label\")\n#predictor = ModelPredictor(keras_model=trained_model, features_col=\"pcaFeatures\")\n#test_set = predictor.predict(test_set)\n#index_transformer = LabelIndexTransformer(output_dim=numClasses)\n#test_set = index_transformer.transform(test_set)\n#score = evaluator.evaluate(test_set)\n#print(\" - Accuracy: \" + str(score))\n#print(\" - Training time: \" + str(trainer.get_training_time()))\n\naccuracy = evaluate_accuracy(trained_model, test_set, \"label\", \"label_index\", \"prediction_index\", \"pcaFeatures\")\ndt = trainer.get_training_time()\nadd_result('adag', accuracy, dt)"
        }, 
        {
            "source": "epoch<br>\n50 - 0.8193942088140799<br>\n100 - 0.8898135212294236<br>\n200 - 0.9727177334732424 (2 200 hidden layers) <br>\n100 - 0.9832014410330102 adag (256, 128) <br>\n200 - 0.9884074419358762 (256, 128, 64) <br>\n200 - 0.9922518356253296 (512, 256, 128, 64, 32) adagrad", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": false
            }, 
            "outputs": [], 
            "source": "predictor = ModelPredictor(keras_model=trained_model, features_col=\"pcaFeatures\")\npredictions = predictor.predict(test_set)\ntransformer = LabelIndexTransformer(output_dim=numClasses)\ntransformer.transform(predictions).select(\"prediction_index\",\"label_index\").where(\"label_index != 0\").take(5)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 (Experimental) with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.2", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }, 
        "anaconda-cloud": {}
    }, 
    "nbformat": 4
}
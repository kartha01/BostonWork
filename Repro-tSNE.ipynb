{
    "nbformat_minor": 0, 
    "cells": [
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": false
            }, 
            "outputs": [
                {
                    "execution_count": 1, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "2.1.0"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "sc.version"
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": false
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "[2.0,20.0,200.0]\n[1.0,100.0,10000.0]\n[3.0,3.0,3.0]\n"
                }
            ], 
            "source": "import org.apache.spark.mllib.linalg.Vectors\nimport org.apache.spark.mllib.stat.{MultivariateStatisticalSummary, Statistics}\n\nval observations = sc.parallelize(\n  Seq(\n    Vectors.dense(1.0, 10.0, 100.0),\n    Vectors.dense(2.0, 20.0, 200.0),\n    Vectors.dense(3.0, 30.0, 300.0)\n  )\n)\n\n// Compute column summary statistics.\nval summary: MultivariateStatisticalSummary = Statistics.colStats(observations)\nprintln(summary.mean)  // a dense vector containing the mean value for each column\nprintln(summary.variance)  // column-wise variance\nprintln(summary.numNonzeros)  // number of nonzeros in each column"
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": false
            }, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Starting download from https://github.com/kartha01/spark-tsne/raw/master/bin/spark-tsne-core_2.11-0.1-SNAPSHOT.jar\nFinished download of spark-tsne-core_2.11-0.1-SNAPSHOT.jar\n"
                }
            ], 
            "source": "%AddJar  https://github.com/kartha01/spark-tsne/raw/master/bin/spark-tsne-core_2.11-0.1-SNAPSHOT.jar -f"
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": false
            }, 
            "outputs": [
                {
                    "execution_count": 3, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "Name: Compile Error\nMessage: error: error while loading DoubleRDDFunctions, class file '/usr/local/src/spark21master/spark-2.1.0-bin-2.7.3/ego/spark-ego_2.11-2.1.0.jar(org/apache/spark/rdd/DoubleRDDFunctions.class)' has location not matching its contents: contains class DoubleRDDFunctions\nerror: error while loading OrderedRDDFunctions, class file '/usr/local/src/spark21master/spark-2.1.0-bin-2.7.3/ego/spark-ego_2.11-2.1.0.jar(org/apache/spark/rdd/OrderedRDDFunctions.class)' has location not matching its contents: contains class OrderedRDDFunctions\nerror: error while loading SequenceFileRDDFunctions, class file '/usr/local/src/spark21master/spark-2.1.0-bin-2.7.3/ego/spark-ego_2.11-2.1.0.jar(org/apache/spark/rdd/SequenceFileRDDFunctions.class)' has location not matching its contents: contains class SequenceFileRDDFunctions\nerror: error while loading AsyncRDDActions, class file '/usr/local/src/spark21master/spark-2.1.0-bin-2.7.3/ego/spark-ego_2.11-2.1.0.jar(org/apache/spark/rdd/AsyncRDDActions.class)' has location not matching its contents: contains class AsyncRDDActions\nerror: error while loading PairRDDFunctions, class file '/usr/local/src/spark21master/spark-2.1.0-bin-2.7.3/ego/spark-ego_2.11-2.1.0.jar(org/apache/spark/rdd/PairRDDFunctions.class)' has location not matching its contents: contains class PairRDDFunctions\n<console>:35: error: type mismatch;\n found   : org.apache.spark.rdd.org.apache.spark.rdd.org.apache.spark.rdd.org.apache.spark.rdd.org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector]\n required: org.apache.spark.rdd.org.apache.spark.rdd.org.apache.spark.rdd.org.apache.spark.rdd.org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector]\n       val summary: MultivariateStatisticalSummary = Statistics.colStats(observations)\n                                                                         ^\nStackTrace: "
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "import org.apache.spark.mllib.linalg.Vectors\nimport org.apache.spark.mllib.stat.{MultivariateStatisticalSummary, Statistics}\n\nval observations = sc.parallelize(\n  Seq(\n    Vectors.dense(1.0, 10.0, 100.0),\n    Vectors.dense(2.0, 20.0, 200.0),\n    Vectors.dense(3.0, 30.0, 300.0)\n  )\n)\n\n// Compute column summary statistics.\nval summary: MultivariateStatisticalSummary = Statistics.colStats(observations)\nprintln(summary.mean)  // a dense vector containing the mean value for each column\nprintln(summary.variance)  // column-wise variance\nprintln(summary.numNonzeros)  // number of nonzeros in each column"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {
                "collapsed": true
            }, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Scala 2.11 with Spark 2.1", 
            "name": "scala-spark21", 
            "language": "scala"
        }, 
        "language_info": {
            "mimetype": "text/x-scala", 
            "version": "2.11.8", 
            "name": "scala", 
            "pygments_lexer": "scala", 
            "file_extension": ".scala", 
            "codemirror_mode": "text/x-scala"
        }
    }, 
    "nbformat": 4
}